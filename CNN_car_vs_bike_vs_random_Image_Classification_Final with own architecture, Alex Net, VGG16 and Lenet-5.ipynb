{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN car vs bike vs random Image Classification_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shuvamjoy34/NumberCrunchers/blob/master/CNN_car_vs_bike_vs_random_Image_Classification_Final%20with%20own%20architecture%2C%20Alex%20Net%2C%20VGG16%20and%20Lenet-5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anIWn3g4IiBr"
      },
      "source": [
        "# **Convolutional Neural Network Based Car vs Bike vs Random Images Multi Class Classification**(Own Architechture,AlexNet,VGG16 and LeNet-5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHQrsv4mJQSW"
      },
      "source": [
        "**Importing required python packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IwzPSB_5BdE"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from keras.utils.data_utils import Sequence\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.keras import balanced_batch_generator\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras \n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cv2 import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from numpy import array \n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "#sess = tf.Session(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49hqPMWwL2gC"
      },
      "source": [
        "**Connecting google colab notebook to my google drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws4O_ErfJ2Dh",
        "outputId": "f332eea8-e21a-4618-c4cf-5ad1705e967b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4vi8xaKMvbj"
      },
      "source": [
        "**Importing the image files with JPG format**\n",
        "\n",
        "\n",
        "**Resizing and Labelling the images**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvMbsJ3t5Pec"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "car=os.listdir(\"/content/drive/My Drive/Images/car/\")\n",
        "for cars in car:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/car/\"+ cars)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128,128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(0)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "\n",
        "bike=os.listdir(\"/content/drive/My Drive/Images/bike/\")\n",
        "for bikes in bike:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/bike/\"+ bikes)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128,128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(1)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "random=os.listdir(\"/content/drive/My Drive/Images/random/\")\n",
        "for randoms in random:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/random/\"+ randoms)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128,128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(2)\n",
        "    except AttributeError:\n",
        "        print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5VbX_iG5tDU"
      },
      "source": [
        "images=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIgw9cX7Brg"
      },
      "source": [
        "s=np.arange(images.shape[0])\n",
        "np.random.shuffle(s)\n",
        "images=images[s]\n",
        "labels=labels[s]\n",
        "num_classes=len(np.unique(labels))\n",
        "len_data=len(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ul0FTN2OW71"
      },
      "source": [
        "**Diving the image dataset into training, validation and testing dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuERdWF7C2h",
        "outputId": "6fb0090b-b51c-4ade-9c31-d0b632e1c3c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "images =images.astype(np.float32)\n",
        "images = images/255\n",
        "\n",
        "train_x , x , train_y , y = train_test_split(images , labels , \n",
        "                                            test_size = 0.2 ,\n",
        "                                            random_state = 111)\n",
        "\n",
        "eval_x , test_x , eval_y , test_y = train_test_split(x , y , \n",
        "                                                    test_size = 0.5 , \n",
        "                                                    random_state = 111)\n",
        "\n",
        "plt.figure(1 , figsize = (15 ,5))\n",
        "n = 0 \n",
        "for z , j in zip([train_y , eval_y , test_y] , ['train labels','eval labels','test labels']):\n",
        "    n += 1\n",
        "    plt.subplot(1 , 3  , n)\n",
        "    sns.countplot(x = z )\n",
        "    plt.title(j)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7FXYtXDRP6d"
      },
      "source": [
        "x=x.reshape(x.shape[0], -1)\n",
        "y=y.reshape(y.shape[0], -1)\n",
        "\n",
        "train_x=train_x.reshape(train_x.shape[0], -1)\n",
        "train_y=train_y.reshape(train_y.shape[0], -1)\n",
        "eval_x=eval_x.reshape(eval_x.shape[0], -1)\n",
        "eval_y=eval_y.reshape(eval_y.shape[0], -1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4WA6XozR4RF",
        "outputId": "4a56bd61-32f3-4be1-8eae-e8ba2b2a32a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "\n",
        "#from imblearn.over_sampling import SMOTE\n",
        "#Over-sampling: SMOTE\n",
        "#SMOTE (Synthetic Minority Oversampling TEchnique) consists of synthesizing elements for the minority class, \n",
        "#based on those that already exist. It works randomly picking a point from the minority class and computing \n",
        "#the k-nearest neighbors for this point.The synthetic points are added between the chosen point and its neighbors.\n",
        "#We'll use ratio='minority' to resample the minority class.\n",
        "smote = SMOTE('minority',kind='regular',k_neighbors=2)\n",
        "\n",
        "#train_x_sm, train_y_sm = smote.fit_sample(train_x,train_y)\n",
        "#print(train_x_sm.shape, train_y_sm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(102, 49152) (102,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GuPx6wdTv3Y"
      },
      "source": [
        "**Encoding the labels of the target class of training,validation and testing dataset from(0,1,2) to (0,1) where 1 pops up when there is a class in the array else 0 pops up**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGsbD8a_DsY"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)\n",
        "eval_y = lb.transform(eval_y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QuZ9pYQLquy"
      },
      "source": [
        "from tensorflow.python.keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "#kernel_regularizer=regularizers.l2(0.05)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACWg91qrU_Qf"
      },
      "source": [
        "**Creating a basic Convolutional Neural Network architecture and using Random Search and Grid Search to find the best Hyper Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTaPHgBu_ULu"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "def create_classifier(activation,dropout_rate_opts,optimizer='adam'):\n",
        "\n",
        "#BasicConvNet\n",
        "    classifier = Sequential()\n",
        "\n",
        "    classifier.add(Conv2D(filters=32,kernel_size=(3,3),padding='same',activation=activation, input_shape=(128,128,3)))\n",
        "    keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=48,kernel_size=(3,3),padding='valid',activation=activation, kernel_regularizer=regularizers.l2(0.05)))\n",
        "    keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=256,kernel_size=(3,3),padding='valid',activation=activation, kernel_regularizer=regularizers.l2(0.05)))\n",
        "    keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Dropout(dropout_rate_opts))\n",
        "\n",
        "\n",
        "    classifier.add(Flatten())# Flattening the \n",
        "\n",
        "    #classifier.add(Dense(200,activation=\"relu\")) #200 is the number of nuerons in hidden layers\n",
        "    classifier.add(Dense(256,activation=activation))\n",
        "    classifier.add(Dense(84,activation=activation))\n",
        "    #classifier.add(Dense(32,activation=activation))  \n",
        "\n",
        "    classifier.add(Dropout(dropout_rate_opts))\n",
        "\n",
        "\n",
        "\n",
        "    classifier.add(Dense(3,activation=\"softmax\"))  #3 represent output layer neurons for three different classes \n",
        "\n",
        "    classifier.summary()\n",
        "    classifier.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdAM3WSHNyEV"
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqrIJvn2Og0O",
        "outputId": "163ec931-aa8c-4f3d-e746-91c6a8f9266a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "_activations=['tanh','relu','selu']\n",
        "_optimizers=['sgd', 'adam']\n",
        "dropout_rate_opts  = [0,  0.2,  0.5]\n",
        "_batch_size=[16,32,64]\n",
        "\n",
        "params=dict(activation=_activations,\n",
        "            optimizer=_optimizers,\n",
        "            batch_size=_batch_size,\n",
        "            dropout_rate_opts=dropout_rate_opts\n",
        "            )\n",
        "print(params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': ['tanh', 'relu', 'selu'], 'optimizer': ['sgd', 'adam'], 'batch_size': [16, 32, 64], 'dropout_rate_opts': [0, 0.2, 0.5]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un-Pv1-XHvBQ",
        "outputId": "eae69a44-440a-49d1-ed3e-351f5c869848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "classifier = KerasClassifier(build_fn=create_classifier,epochs=100,batch_size=16)\n",
        "classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier at 0x7fcb5780cfd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H47ucQsgIvj_",
        "outputId": "04ee3432-f416-48be-82ab-048dc01f634f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "np.random.seed(42)\n",
        "rscv = RandomizedSearchCV(classifier, param_distributions=params, cv=3,   n_iter=10)\n",
        "rscv_results = rscv.fit(train_x_sm,train_y_sm)\n",
        "print('Best score is: {} using {}'.format(rscv_results.best_score_,\n",
        "rscv_results.best_params_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 128, 128, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 62, 62, 48)        13872     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 31, 31, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 29, 29, 256)       110848    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 256)               12845312  \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 84)                21588     \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 3)                 255       \n",
            "=================================================================\n",
            "Total params: 12,992,771\n",
            "Trainable params: 12,992,771\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 360ms/step - loss: 6.7329 - accuracy: 0.3962\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 1s 361ms/step - loss: 5.5912 - accuracy: 0.4528\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 1s 354ms/step - loss: 4.6466 - accuracy: 0.4528\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 1s 361ms/step - loss: 3.8708 - accuracy: 0.4528\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 1s 365ms/step - loss: 3.2380 - accuracy: 0.4528\n",
            "Epoch 6/100\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 2.9028 - accuracy: 0.3750"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-e8e722513ad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrscv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_distributions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrscv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrscv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_sm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_sm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m print('Best score is: {} using {}'.format(rscv_results.best_score_,\n\u001b[1;32m      7\u001b[0m rscv_results.best_params_))\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJeljKDG5hjo"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "def create_classifier():\n",
        "\n",
        "#BasicConvNet\n",
        "    classifier = Sequential()\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation=\"relu\", input_shape=(256,256,3)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation=\"relu\", kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation=\"relu\", kernel_regularizer=regularizers.l2(0.05)))\n",
        "    #keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    #classifier.add(Dropout(dropout_rate_opts))\n",
        "\n",
        "\n",
        "    classifier.add(Flatten())# Flattening the \n",
        "\n",
        "    #classifier.add(Dense(200,activation=\"relu\")) #200 is the number of nuerons in hidden layers\n",
        "    classifier.add(Dense(128,activation=\"relu\"))\n",
        "    classifier.add(Dense(64,activation=\"relu\"))\n",
        "    classifier.add(Dense(32,activation=\"relu\"))  \n",
        "\n",
        "    #classifier.add(Dropout(dropout_rate_opts))\n",
        "\n",
        "\n",
        "\n",
        "    classifier.add(Dense(3,activation=\"softmax\"))  #3 represent output layer neurons for three different classes \n",
        "\n",
        "    classifier.summary()\n",
        "    classifier.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20l9gZwspu_6",
        "outputId": "10c5b549-96a2-4a86-9438-abb9d5889c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        }
      },
      "source": [
        "# create model\n",
        "classifier = KerasClassifier(build_fn=create_classifier, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [10, 20, 30, 40, 50]\n",
        "epochs = [10, 50, 100, 150, 200]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x,y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-158358a724b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7RnJ1QXrtcY"
      },
      "source": [
        "def create_classifier(optimizer='adam'):\n",
        "\n",
        "#BasicConvNet\n",
        "    classifier = Sequential()\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "    #keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    #classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    classifier.add(Flatten())# Flattening the \n",
        "\n",
        "    #classifier.add(Dense(200,activation=\"relu\")) #200 is the number of nuerons in hidden layers\n",
        "    classifier.add(Dense(128,activation=\"relu\"))\n",
        "    classifier.add(Dense(64,activation=\"relu\"))\n",
        "    classifier.add(Dense(32,activation=\"relu\"))  \n",
        "\n",
        "    #classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "    classifier.add(Dense(3,activation=\"softmax\"))  #3 represent output layer neurons for three different classes \n",
        "\n",
        "    classifier.summary()\n",
        "    classifier.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kBKxU63sABc",
        "outputId": "91fcf788-cadd-4847-866e-277e87367f63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        }
      },
      "source": [
        "classifier = KerasClassifier(build_fn=create_classifier, epochs=50, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
        "param_grid = dict(optimizer=optimizer)\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(x,y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_96 (Conv2D)           (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_96 (MaxPooling (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_97 (MaxPooling (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_98 (MaxPooling (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_32 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_128 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_129 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_130 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_131 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Best: 0.857143 using {'optimizer': 'Adamax'}\n",
            "nan (nan) with: {'optimizer': 'SGD'}\n",
            "nan (nan) with: {'optimizer': 'RMSprop'}\n",
            "0.309524 (0.146772) with: {'optimizer': 'Adagrad'}\n",
            "nan (nan) with: {'optimizer': 'Adadelta'}\n",
            "nan (nan) with: {'optimizer': 'Adam'}\n",
            "0.857143 (0.116642) with: {'optimizer': 'Adamax'}\n",
            "nan (nan) with: {'optimizer': 'Nadam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfTCoSnxtDxF"
      },
      "source": [
        "from keras.optimizers import Adamax\n",
        "def create_classifier(learn_rate=0.01, beta_1=0):\n",
        "\n",
        "#BasicConvNet\n",
        "    classifier = Sequential()\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "    #keras.layers.BatchNormalization()\n",
        "    classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    #classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "    classifier.add(Flatten())# Flattening the \n",
        "\n",
        "    #classifier.add(Dense(200,activation=\"relu\")) #200 is the number of nuerons in hidden layers\n",
        "    classifier.add(Dense(128,activation=\"relu\"))\n",
        "    classifier.add(Dense(64,activation=\"relu\"))\n",
        "    classifier.add(Dense(32,activation=\"relu\"))  \n",
        "\n",
        "    #classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "    classifier.add(Dense(3,activation=\"softmax\"))  #3 represent output layer neurons for three different classes \n",
        "\n",
        "    classifier.summary()\n",
        "    optimizer = Adamax(lr=learn_rate, beta_1=beta_1)\n",
        "    classifier.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "    return classifier\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M-zBULS0adN",
        "outputId": "85067b23-980d-440d-c54e-6bd0553ecc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "classifier = KerasClassifier(build_fn=create_classifier, epochs=50, batch_size=10, verbose=0)\n",
        "# define the grid search parameters\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
        "beta_1 = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "param_grid = dict(learn_rate=learn_rate, beta_1=beta_1)\n",
        "grid = GridSearchCV(estimator=classifier, param_grid=param_grid, n_jobs=1, cv=3)\n",
        "grid_result = grid.fit(x,y)\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_105 (Conv2D)          (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_105 (MaxPoolin (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_106 (MaxPoolin (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_107 (MaxPoolin (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_35 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_140 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_141 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_142 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_143 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_108 (Conv2D)          (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_108 (MaxPoolin (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_109 (MaxPoolin (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_110 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_110 (MaxPoolin (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_144 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_145 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_146 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_147 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_111 (Conv2D)          (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_111 (MaxPoolin (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_112 (Conv2D)          (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_112 (MaxPoolin (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_113 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_113 (MaxPoolin (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_37 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_148 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_149 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_150 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_151 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_114 (Conv2D)          (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_114 (MaxPoolin (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_115 (Conv2D)          (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_115 (MaxPoolin (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_116 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_116 (MaxPoolin (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_38 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_152 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_153 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_154 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_155 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_test_function.<locals>.test_function at 0x7f82b76ebbf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_117 (Conv2D)          (None, 254, 254, 64)      1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_117 (MaxPoolin (None, 127, 127, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_118 (Conv2D)          (None, 125, 125, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_118 (MaxPoolin (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_119 (Conv2D)          (None, 60, 60, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_119 (MaxPoolin (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_39 (Flatten)         (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_156 (Dense)            (None, 128)               7372928   \n",
            "_________________________________________________________________\n",
            "dense_157 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_158 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_159 (Dense)            (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 7,459,011\n",
            "Trainable params: 7,459,011\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-6f1ac13f39f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SCq_1GKM5Lb",
        "outputId": "60de8e24-d50d-4037-bca7-13f57fec055a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY7i_KRdO7Qy"
      },
      "source": [
        "#,kernel_regularizer=regularizers.l2(0.05)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stqCn0cw8Ez6",
        "outputId": "c5e7ffa8-41bf-4d00-896a-202aed634905",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        }
      },
      "source": [
        "from tensorflow.keras.activations import selu\n",
        "#BasicConvNet\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters=96,kernel_size=(3,3),padding='valid',activation=\"relu\",input_shape=(128,128,3)))\n",
        "#keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "classifier.add(Conv2D(filters=128,kernel_size=(3,3),padding='valid',activation=\"relu\",kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "classifier.add(Conv2D(filters=256,kernel_size=(3,3),padding='valid',activation=\"relu\",kernel_regularizer=regularizers.l2(0.05)))\n",
        "keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "classifier.add(Flatten())# Flattening  \n",
        "\n",
        "#classifier.add(Dense(200,activation=\"relu\"))\n",
        "\n",
        "classifier.add(Dense(512,activation=\"relu\"))\n",
        "classifier.add(Dense(256,activation=\"relu\"))\n",
        "#classifier.add(Dense(128,activation=\"relu\")) #200 is the number of nuerons in hidden layers\n",
        "\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "\n",
        "classifier.add(Dense(3,activation=\"softmax\"))  #3 represent output layer neurons for three different classes \n",
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 126, 126, 96)      2688      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_46 (MaxPooling (None, 63, 63, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 61, 61, 128)       110720    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_47 (MaxPooling (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 28, 28, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_48 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 50176)             0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 512)               25690624  \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 26,231,299\n",
            "Trainable params: 26,231,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_c3aQTCBO0W",
        "outputId": "ceb9f27e-81ee-4cc2-f8ca-22e921b58f1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.activations import selu\n",
        "checkpoint = ModelCheckpoint(\"convnet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "#from sklearn.utils import class_weight\n",
        "#class_weight = class_weight.compute_class_weight('balanced' ,np.unique(y_train_labels) ,y_train_labels)\n",
        "from keras.optimizers import Adam\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#from keras.optimizers import SGD\n",
        "#sgd=SGD(lr=0.01,momentum=0.6,nesterov=False)\n",
        "#adam = Adam(lr=0.01)\n",
        "\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "conv= classifier.fit(train_x,train_y,batch_size =32,epochs=100,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])\n",
        "conv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 14.7059 - accuracy: 0.4250\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20000, saving model to convnet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 14.7059 - accuracy: 0.4250 - val_loss: 12.8034 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 12.5166 - accuracy: 0.3250\n",
            "Epoch 00002: val_accuracy improved from 0.20000 to 0.70000, saving model to convnet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 12.5166 - accuracy: 0.3250 - val_loss: 11.0118 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 10.6101 - accuracy: 0.4500\n",
            "Epoch 00003: val_accuracy did not improve from 0.70000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 10.6101 - accuracy: 0.4500 - val_loss: 9.3162 - val_accuracy: 0.7000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 8.9863 - accuracy: 0.4625\n",
            "Epoch 00004: val_accuracy improved from 0.70000 to 0.80000, saving model to convnet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 8.9863 - accuracy: 0.4625 - val_loss: 7.9126 - val_accuracy: 0.8000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 7.5747 - accuracy: 0.6125\n",
            "Epoch 00005: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 7.5747 - accuracy: 0.6125 - val_loss: 6.5345 - val_accuracy: 0.7000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 6.4442 - accuracy: 0.4500\n",
            "Epoch 00006: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 6.4442 - accuracy: 0.4500 - val_loss: 5.6471 - val_accuracy: 0.6000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.4368 - accuracy: 0.5250\n",
            "Epoch 00007: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 5.4368 - accuracy: 0.5250 - val_loss: 4.8352 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 4.6750 - accuracy: 0.5375\n",
            "Epoch 00008: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 4.6750 - accuracy: 0.5375 - val_loss: 4.1840 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.9127 - accuracy: 0.6625\n",
            "Epoch 00009: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 3.9127 - accuracy: 0.6625 - val_loss: 3.4095 - val_accuracy: 0.6000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 3.2380 - accuracy: 0.7375\n",
            "Epoch 00010: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 3.2380 - accuracy: 0.7375 - val_loss: 3.0545 - val_accuracy: 0.6000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 2.7302 - accuracy: 0.8125\n",
            "Epoch 00011: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 2.7302 - accuracy: 0.8125 - val_loss: 2.4187 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 2.3191 - accuracy: 0.8375\n",
            "Epoch 00012: val_accuracy improved from 0.80000 to 0.90000, saving model to convnet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 2.3191 - accuracy: 0.8375 - val_loss: 2.0156 - val_accuracy: 0.9000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 2.0032 - accuracy: 0.8500\n",
            "Epoch 00013: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 2.0032 - accuracy: 0.8500 - val_loss: 2.0314 - val_accuracy: 0.7000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.6927 - accuracy: 0.9000\n",
            "Epoch 00014: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.6927 - accuracy: 0.9000 - val_loss: 1.5689 - val_accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.4497 - accuracy: 0.9250\n",
            "Epoch 00015: val_accuracy improved from 0.90000 to 1.00000, saving model to convnet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 1.4497 - accuracy: 0.9250 - val_loss: 1.2164 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.3247 - accuracy: 0.9250\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.3247 - accuracy: 0.9250 - val_loss: 1.0953 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.1022 - accuracy: 0.9625\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.1022 - accuracy: 0.9625 - val_loss: 1.1155 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.0367 - accuracy: 0.9500\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.0367 - accuracy: 0.9500 - val_loss: 0.8684 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.9137 - accuracy: 0.9625\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.9137 - accuracy: 0.9625 - val_loss: 1.3489 - val_accuracy: 0.8000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8714 - accuracy: 0.9250\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.8714 - accuracy: 0.9250 - val_loss: 0.7328 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.8971 - accuracy: 0.9375\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.8971 - accuracy: 0.9375 - val_loss: 0.7350 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7618 - accuracy: 0.9500\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.7618 - accuracy: 0.9500 - val_loss: 1.3386 - val_accuracy: 0.7000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.9625\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6876 - accuracy: 0.9625 - val_loss: 0.5693 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6368 - accuracy: 0.9625\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.6368 - accuracy: 0.9625 - val_loss: 0.5369 - val_accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.5685 - accuracy: 0.9750\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5685 - accuracy: 0.9750 - val_loss: 0.6314 - val_accuracy: 0.9000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 1.0000\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5287 - accuracy: 1.0000 - val_loss: 0.9269 - val_accuracy: 0.8000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.5124 - accuracy: 0.9875\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.5124 - accuracy: 0.9875 - val_loss: 0.6105 - val_accuracy: 0.9000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 1.0000\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4565 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.4159 - accuracy: 1.0000\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.4159 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3867 - accuracy: 1.0000\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3867 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3523 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3321 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3130 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.3130 - accuracy: 1.0000 - val_loss: 0.3041 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2897 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2897 - accuracy: 1.0000 - val_loss: 0.2763 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2711 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.2711 - accuracy: 1.0000 - val_loss: 0.2566 - val_accuracy: 1.0000\n",
            "Epoch 00035: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb57655fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjJBZEdUszUB",
        "outputId": "a995c8d6-1130-463d-b281-5eef2e5966ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "# plot the training and validation accuracy\n",
        "acc = conv.history['accuracy']\n",
        "val_acc = conv.history['val_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, label='Training acc')\n",
        "plt.plot(epochs, val_acc, label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.ylim(0.0,1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk4iuwnVC-TV",
        "outputId": "c354f027-3787-4b40-c28e-588723f90403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "#Loss and Accuracy in one graph(Training & Validation)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(conv.history[\"accuracy\"])\n",
        "#plt.plot(conv.history['val_accuracy'])\n",
        "plt.plot(conv.history['loss'])\n",
        "plt.plot(conv.history['val_loss'])\n",
        "plt.title(\"Training and Validation Loss \")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Training loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgj8LbNMAtzE",
        "outputId": "f40bfbea-5b14-44c2-eeeb-64ef9a10e711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(conv.history[\"accuracy\"])\n",
        "#plt.plot(conv.history['val_accuracy'])\n",
        "plt.plot(conv.history['loss'])\n",
        "plt.plot(conv.history['val_loss'])\n",
        "plt.title(\"Training and Validation Loss \")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Training loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnZST5sdSHhf"
      },
      "source": [
        "classifier.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv1rm3NOSUHc",
        "outputId": "cc39ec6e-6c9a-4d8a-a936-90193cdd2bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        }
      },
      "source": [
        "#STEP_SIZE_TRAIN=balanced_gen.n//balanced_gen.batch_size\n",
        "#STEP_SIZE_VALID=balanced_gen.n//balanced_gen.batch_size\n",
        "#STEP_SIZE_TEST=balanced_gen.n//balanced_gen.batch_size\n",
        "#ep = 100\n",
        "#batch_size=32\n",
        "classifier.fit_generator(balanced_gen,steps_per_epoch, \n",
        "                        )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-b2126ea2f514>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#ep = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#batch_size=32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m classifier.fit_generator(balanced_gen,steps_per_epoch, \n\u001b[0m\u001b[1;32m      7\u001b[0m                         )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__\n        losses = ag_call(y_true, y_pred)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeoWYDPiBVTM"
      },
      "source": [
        "#using Image Augmentation Approach(By using Image Data Generator)\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.,\n",
        "                                  horizontal_flip = True,\n",
        "                                  zoom_range = 0.3,\n",
        "                                  rotation_range = 30)\n",
        "val_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow(train_x,train_y, batch_size=32)\n",
        "val_gen = val_datagen.flow(eval_x,eval_y, batch_size=32)\n",
        "test_gen = val_datagen.flow(test_x,test_y, batch_size =32, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmrxG-bLv_tB",
        "outputId": "4f7a725c-ecf6-4451-c7fd-f4bb3b610726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "ep = 100\n",
        "classifier.fit_generator(generator = train_gen, validation_data= val_gen,\n",
        "                           steps_per_epoch=STEP_SIZE_TRAIN, epochs=ep, \n",
        "                           validation_steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-96-372460def1fa>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 296ms/step - loss: 2.7503 - accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 3.7123 - accuracy: 0.2292\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.9649 - accuracy: 0.2708\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 289ms/step - loss: 1.6868 - accuracy: 0.3333\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 1.4224 - accuracy: 0.3542\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 1.4197 - accuracy: 0.3333\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 1.2024 - accuracy: 0.5833\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 1.3252 - accuracy: 0.4792\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 1.4492 - accuracy: 0.5208\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 279ms/step - loss: 1.4112 - accuracy: 0.3906\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.4233 - accuracy: 0.4062\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.2784 - accuracy: 0.4375\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 271ms/step - loss: 1.4645 - accuracy: 0.3542\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 284ms/step - loss: 1.3911 - accuracy: 0.4219\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 161ms/step - loss: 1.3876 - accuracy: 0.4167\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 277ms/step - loss: 1.3894 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.3271 - accuracy: 0.3125\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 1.2680 - accuracy: 0.4583\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 283ms/step - loss: 1.3987 - accuracy: 0.3750\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.3064 - accuracy: 0.4219\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.3131 - accuracy: 0.4375\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.2852 - accuracy: 0.4844\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 283ms/step - loss: 1.4955 - accuracy: 0.2344\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 1.3680 - accuracy: 0.4219\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 1.4285 - accuracy: 0.3542\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 163ms/step - loss: 1.3004 - accuracy: 0.4375\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 279ms/step - loss: 1.1286 - accuracy: 0.4688\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.1771 - accuracy: 0.4688\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 288ms/step - loss: 1.2644 - accuracy: 0.3906\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 273ms/step - loss: 1.2736 - accuracy: 0.3958\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 270ms/step - loss: 1.0638 - accuracy: 0.5208\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 1.4420 - accuracy: 0.2917\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 156ms/step - loss: 1.2202 - accuracy: 0.4792\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 1.1182 - accuracy: 0.5312\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 276ms/step - loss: 1.2648 - accuracy: 0.4531\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 1.3602 - accuracy: 0.4167\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 279ms/step - loss: 1.2535 - accuracy: 0.4844\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 287ms/step - loss: 1.2394 - accuracy: 0.4531\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 282ms/step - loss: 1.2966 - accuracy: 0.3906\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 281ms/step - loss: 1.1856 - accuracy: 0.5000\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 273ms/step - loss: 1.4351 - accuracy: 0.2917\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 273ms/step - loss: 1.2483 - accuracy: 0.3125\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 1.1862 - accuracy: 0.2708\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 1.1186 - accuracy: 0.4583\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 1.2152 - accuracy: 0.4583\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 155ms/step - loss: 1.3440 - accuracy: 0.3542\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 160ms/step - loss: 1.2455 - accuracy: 0.4375\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 284ms/step - loss: 1.3404 - accuracy: 0.2500\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 1.1380 - accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 1.2650 - accuracy: 0.3750\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 280ms/step - loss: 1.1889 - accuracy: 0.4062\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 1.1360 - accuracy: 0.4792\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 277ms/step - loss: 1.2443 - accuracy: 0.4375\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 279ms/step - loss: 1.2998 - accuracy: 0.3958\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 281ms/step - loss: 1.1377 - accuracy: 0.4531\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.1038 - accuracy: 0.5208\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 281ms/step - loss: 1.0942 - accuracy: 0.4792\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.1552 - accuracy: 0.5000\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 1.1706 - accuracy: 0.4844\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 276ms/step - loss: 1.1552 - accuracy: 0.4844\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 280ms/step - loss: 1.3042 - accuracy: 0.3125\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.1116 - accuracy: 0.4792\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 1.2549 - accuracy: 0.5208\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 278ms/step - loss: 1.2095 - accuracy: 0.4062\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 1.1019 - accuracy: 0.4792\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 273ms/step - loss: 1.1316 - accuracy: 0.4583\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 1.1271 - accuracy: 0.3750\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 1.0909 - accuracy: 0.4375\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 149ms/step - loss: 1.1681 - accuracy: 0.3333\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 285ms/step - loss: 1.0836 - accuracy: 0.4583\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 154ms/step - loss: 1.0252 - accuracy: 0.5208\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 1.1838 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 1.0074 - accuracy: 0.4375\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 270ms/step - loss: 1.1461 - accuracy: 0.4375\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 268ms/step - loss: 1.2052 - accuracy: 0.4531\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 280ms/step - loss: 1.2357 - accuracy: 0.3281\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 0.9942 - accuracy: 0.5208\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 266ms/step - loss: 1.1034 - accuracy: 0.3958\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 283ms/step - loss: 1.1561 - accuracy: 0.4167\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 1.2047 - accuracy: 0.4062\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 271ms/step - loss: 1.1277 - accuracy: 0.3906\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 1.0722 - accuracy: 0.4844\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 266ms/step - loss: 1.1438 - accuracy: 0.4792\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 1.1585 - accuracy: 0.3438\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 274ms/step - loss: 1.1045 - accuracy: 0.5000\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 277ms/step - loss: 1.0740 - accuracy: 0.4219\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 1.1117 - accuracy: 0.4583\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 153ms/step - loss: 1.0665 - accuracy: 0.5208\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 275ms/step - loss: 1.1301 - accuracy: 0.4375\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 151ms/step - loss: 1.1116 - accuracy: 0.4375\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 265ms/step - loss: 1.0696 - accuracy: 0.4375\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 272ms/step - loss: 1.0186 - accuracy: 0.4531\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 268ms/step - loss: 1.1304 - accuracy: 0.3906\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 268ms/step - loss: 1.0760 - accuracy: 0.5156\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 1.1616 - accuracy: 0.3125\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 265ms/step - loss: 1.1701 - accuracy: 0.3594\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 1.1145 - accuracy: 0.3750\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 289ms/step - loss: 1.0841 - accuracy: 0.5312\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 270ms/step - loss: 1.1500 - accuracy: 0.5000\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 283ms/step - loss: 1.0824 - accuracy: 0.4167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1bc13602e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4OOZImRwOZW",
        "outputId": "f6aacd68-9155-4002-fc14-d4e3746b11c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model for convnet\n",
        "score = classifier.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.26072797179222107\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJUUhfA2RM2",
        "outputId": "7e41919b-2878-495a-ad6a-da582903c68f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = classifier.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       1.00      1.00      1.00         3\n",
            "  class 1(bike)       1.00      1.00      1.00         2\n",
            "class 2(random)       1.00      1.00      1.00         5\n",
            "\n",
            "       accuracy                           1.00        10\n",
            "      macro avg       1.00      1.00      1.00        10\n",
            "   weighted avg       1.00      1.00      1.00        10\n",
            "\n",
            "[[3 0 0]\n",
            " [0 2 0]\n",
            " [0 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YIr9Px0pjcc"
      },
      "source": [
        "\n",
        "#AlexNet\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\",kernel_regularizer=regularizers.l2(0.05)),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(1024, activation='relu'),\n",
        "    keras.layers.Dropout(0.5),\n",
        "     keras.layers.Dense(1000, activation='relu'),\n",
        "    #keras.layers.Dropout(0.5),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvzMvEJPj-n4",
        "outputId": "037ffff5-17fb-4b6e-f683-3eb0c21ad8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Importing library\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)\n",
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()\n",
        "\n",
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "\n",
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Dropout(0.4))\n",
        "AlexNet.add(Flatten())\n",
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(1024, input_shape=(128,128,3,)))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n",
        "\n",
        "#2nd Fully Connected Layer\n",
        "AlexNet.add(Dense(1024))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.5))\n",
        "\n",
        "#3rd Fully Connected Layer\n",
        "AlexNet.add(Dense(1000))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "#Add Dropout\n",
        "AlexNet.add(Dropout(0.5))\n",
        "\n",
        "#Output Layer\n",
        "AlexNet.add(Dense(3))\n",
        "#AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('softmax'))\n",
        "\n",
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_216 (Conv2D)          (None, 57, 57, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_112 (Activation)  (None, 57, 57, 96)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_146 (MaxPoolin (None, 29, 29, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_217 (Conv2D)          (None, 29, 29, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_113 (Activation)  (None, 29, 29, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_147 (MaxPoolin (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_218 (Conv2D)          (None, 15, 15, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_114 (Activation)  (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_219 (Conv2D)          (None, 15, 15, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_115 (Activation)  (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_220 (Conv2D)          (None, 15, 15, 256)       884992    \n",
            "_________________________________________________________________\n",
            "activation_116 (Activation)  (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_148 (MaxPoolin (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_124 (Dropout)        (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_49 (Flatten)         (None, 16384)             0         \n",
            "_________________________________________________________________\n",
            "dense_169 (Dense)            (None, 1024)              16778240  \n",
            "_________________________________________________________________\n",
            "activation_117 (Activation)  (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_125 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_170 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "activation_118 (Activation)  (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_126 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_171 (Dense)            (None, 1000)              1025000   \n",
            "_________________________________________________________________\n",
            "activation_119 (Activation)  (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dropout_127 (Dropout)        (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "dense_172 (Dense)            (None, 3)                 3003      \n",
            "_________________________________________________________________\n",
            "activation_120 (Activation)  (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 22,603,043\n",
            "Trainable params: 22,603,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0YQ7j7Lpvv_",
        "outputId": "fc4ab179-fdb8-4757-fbe0-1f875a89ffa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_226 (Conv2D)          (None, 30, 30, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_104 (Bat (None, 30, 30, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_152 (MaxPoolin (None, 14, 14, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_227 (Conv2D)          (None, 14, 14, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_105 (Bat (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_153 (MaxPoolin (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_228 (Conv2D)          (None, 6, 6, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_106 (Bat (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_229 (Conv2D)          (None, 6, 6, 384)         147840    \n",
            "_________________________________________________________________\n",
            "batch_normalization_107 (Bat (None, 6, 6, 384)         1536      \n",
            "_________________________________________________________________\n",
            "conv2d_230 (Conv2D)          (None, 6, 6, 256)         98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_108 (Bat (None, 6, 6, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_154 (MaxPoolin (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_51 (Flatten)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_177 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 1024)              1049600   \n",
            "_________________________________________________________________\n",
            "dropout_129 (Dropout)        (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_179 (Dense)            (None, 1000)              1025000   \n",
            "_________________________________________________________________\n",
            "dense_180 (Dense)            (None, 3)                 3003      \n",
            "=================================================================\n",
            "Total params: 4,913,827\n",
            "Trainable params: 4,911,075\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW43wFVHw5GL"
      },
      "source": [
        "#callbacks=[checkpoint,early]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg64Pmo1qFhM",
        "outputId": "e2e79f64-7860-4b96-f42c-f2b8358e31bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"alexnet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "#from keras.optimizers import Adam\n",
        "#from keras.optimizers import SGD\n",
        "#opt = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "lizon=model.fit(train_x,train_y,batch_size = 64,epochs=50,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])\n",
        "lizon"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 9.7590 - accuracy: 0.4000\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20000, saving model to alexnet_1.h5\n",
            "2/2 [==============================] - 1s 542ms/step - loss: 9.7590 - accuracy: 0.4000 - val_loss: 8.1324 - val_accuracy: 0.2000\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 14.7457 - accuracy: 0.3375\n",
            "Epoch 00002: val_accuracy improved from 0.20000 to 0.70000, saving model to alexnet_1.h5\n",
            "2/2 [==============================] - 1s 457ms/step - loss: 14.7457 - accuracy: 0.3375 - val_loss: 7.7557 - val_accuracy: 0.7000\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 9.3111 - accuracy: 0.4750\n",
            "Epoch 00003: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 9.3111 - accuracy: 0.4750 - val_loss: 7.6783 - val_accuracy: 0.7000\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 7.6669 - accuracy: 0.6000\n",
            "Epoch 00004: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 7.6669 - accuracy: 0.6000 - val_loss: 7.8273 - val_accuracy: 0.1000\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 7.5806 - accuracy: 0.5875\n",
            "Epoch 00005: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 329ms/step - loss: 7.5806 - accuracy: 0.5875 - val_loss: 7.5250 - val_accuracy: 0.7000\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 7.2099 - accuracy: 0.7000\n",
            "Epoch 00006: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 7.2099 - accuracy: 0.7000 - val_loss: 7.3158 - val_accuracy: 0.7000\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.8719 - accuracy: 0.8375\n",
            "Epoch 00007: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 345ms/step - loss: 6.8719 - accuracy: 0.8375 - val_loss: 7.6687 - val_accuracy: 0.7000\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.5203 - accuracy: 0.9000\n",
            "Epoch 00008: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 6.5203 - accuracy: 0.9000 - val_loss: 8.5290 - val_accuracy: 0.7000\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.2842 - accuracy: 0.9125\n",
            "Epoch 00009: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 6.2842 - accuracy: 0.9125 - val_loss: 9.6250 - val_accuracy: 0.7000\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 6.0230 - accuracy: 0.9250\n",
            "Epoch 00010: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 6.0230 - accuracy: 0.9250 - val_loss: 10.2949 - val_accuracy: 0.7000\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.9812 - accuracy: 0.9000\n",
            "Epoch 00011: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 5.9812 - accuracy: 0.9000 - val_loss: 8.4478 - val_accuracy: 0.7000\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.7366 - accuracy: 0.9000\n",
            "Epoch 00012: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 5.7366 - accuracy: 0.9000 - val_loss: 7.2265 - val_accuracy: 0.7000\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.4279 - accuracy: 0.9000\n",
            "Epoch 00013: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 5.4279 - accuracy: 0.9000 - val_loss: 8.2537 - val_accuracy: 0.7000\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.2272 - accuracy: 0.9375\n",
            "Epoch 00014: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 5.2272 - accuracy: 0.9375 - val_loss: 8.8785 - val_accuracy: 0.7000\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 5.0444 - accuracy: 0.9250\n",
            "Epoch 00015: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 5.0444 - accuracy: 0.9250 - val_loss: 7.9762 - val_accuracy: 0.7000\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 4.7094 - accuracy: 0.9750\n",
            "Epoch 00016: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 320ms/step - loss: 4.7094 - accuracy: 0.9750 - val_loss: 7.0530 - val_accuracy: 0.7000\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 4.4674 - accuracy: 1.0000\n",
            "Epoch 00017: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 328ms/step - loss: 4.4674 - accuracy: 1.0000 - val_loss: 6.1954 - val_accuracy: 0.7000\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 4.3778 - accuracy: 0.9375\n",
            "Epoch 00018: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 4.3778 - accuracy: 0.9375 - val_loss: 5.9367 - val_accuracy: 0.7000\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 4.1963 - accuracy: 0.9625\n",
            "Epoch 00019: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 4.1963 - accuracy: 0.9625 - val_loss: 6.0171 - val_accuracy: 0.7000\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.9529 - accuracy: 0.9750\n",
            "Epoch 00020: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 3.9529 - accuracy: 0.9750 - val_loss: 6.1065 - val_accuracy: 0.7000\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.7578 - accuracy: 0.9875\n",
            "Epoch 00021: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 3.7578 - accuracy: 0.9875 - val_loss: 5.9498 - val_accuracy: 0.7000\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - ETA: 0s - loss: 3.6772 - accuracy: 0.9500\n",
            "Epoch 00022: val_accuracy did not improve from 0.70000\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 3.6772 - accuracy: 0.9500 - val_loss: 5.7944 - val_accuracy: 0.7000\n",
            "Epoch 00022: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb363f0a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWTB5BinJv2k",
        "outputId": "0e491d0c-0d81-4df6-f053-139f45796913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lizon.history[\"accuracy\"])\n",
        "plt.plot(lizon.history['val_accuracy'])\n",
        "plt.plot(lizon.history['loss'])\n",
        "plt.plot(lizon.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1B1r82sUEx"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.,\n",
        "                                  horizontal_flip = True,\n",
        "                                  zoom_range = 0.3,\n",
        "                                  rotation_range = 30)\n",
        "val_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow(train_x,train_y, batch_size=32)\n",
        "val_gen = val_datagen.flow(eval_x,eval_y, batch_size=32)\n",
        "test_gen = val_datagen.flow(test_x,test_y, batch_size =32, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPHolMmlsWT0",
        "outputId": "0347631f-701b-4dd5-9617-5364c38dfd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "ep = 100\n",
        "classifier.fit_generator(generator = train_gen, validation_data= val_gen,\n",
        "                           steps_per_epoch=STEP_SIZE_TRAIN, epochs=ep, \n",
        "                           validation_steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-43-372460def1fa>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 260ms/step - loss: 13.1706 - accuracy: 0.4531\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 4.7036 - accuracy: 0.2812\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 2.4718 - accuracy: 0.3125\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 2.6478 - accuracy: 0.3281\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.4242 - accuracy: 0.5208\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 2.0586 - accuracy: 0.3750\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.7608 - accuracy: 0.4688\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.4726 - accuracy: 0.4167\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.5628 - accuracy: 0.2708\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.4352 - accuracy: 0.4583\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.5146 - accuracy: 0.3750\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.6093 - accuracy: 0.2083\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 1.4686 - accuracy: 0.3750\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.5262 - accuracy: 0.2969\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3943 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3305 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.4633 - accuracy: 0.4219\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2938 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.3391 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.4269 - accuracy: 0.3958\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.2853 - accuracy: 0.5625\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.4078 - accuracy: 0.4792\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.3090 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.3374 - accuracy: 0.4219\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.3978 - accuracy: 0.4167\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.4137 - accuracy: 0.3125\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.3347 - accuracy: 0.4219\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.3217 - accuracy: 0.4375\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2602 - accuracy: 0.5625\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 1.3404 - accuracy: 0.4583\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 1.3253 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2566 - accuracy: 0.5833\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 1.2814 - accuracy: 0.5417\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.3491 - accuracy: 0.4583\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.3130 - accuracy: 0.4792\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.2932 - accuracy: 0.4583\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 245ms/step - loss: 1.2566 - accuracy: 0.4844\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.3359 - accuracy: 0.4792\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.3562 - accuracy: 0.4375\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.3591 - accuracy: 0.4167\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2879 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.3309 - accuracy: 0.4583\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.3367 - accuracy: 0.4167\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 1.2921 - accuracy: 0.4531\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 242ms/step - loss: 1.2737 - accuracy: 0.4583\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.3158 - accuracy: 0.4844\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.2376 - accuracy: 0.5208\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2570 - accuracy: 0.4688\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2525 - accuracy: 0.5156\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2553 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1675 - accuracy: 0.5833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 1.2550 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2587 - accuracy: 0.4688\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.2586 - accuracy: 0.4844\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3249 - accuracy: 0.4375\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2855 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.2774 - accuracy: 0.4583\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.2515 - accuracy: 0.4583\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2216 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2721 - accuracy: 0.5208\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.2436 - accuracy: 0.4792\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2357 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2404 - accuracy: 0.4792\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.2609 - accuracy: 0.4375\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2583 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2164 - accuracy: 0.5156\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2646 - accuracy: 0.4531\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2540 - accuracy: 0.4844\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2643 - accuracy: 0.4792\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.2572 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 242ms/step - loss: 1.2325 - accuracy: 0.4531\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2722 - accuracy: 0.4167\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.2524 - accuracy: 0.4688\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2337 - accuracy: 0.4583\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.2185 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.3037 - accuracy: 0.4583\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.2249 - accuracy: 0.5208\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.1717 - accuracy: 0.5625\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.2451 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2073 - accuracy: 0.5208\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2266 - accuracy: 0.4792\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2072 - accuracy: 0.5312\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.2370 - accuracy: 0.4792\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2010 - accuracy: 0.5417\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2507 - accuracy: 0.4688\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.2115 - accuracy: 0.5625\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2301 - accuracy: 0.4844\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 1.2145 - accuracy: 0.5156\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1932 - accuracy: 0.5208\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.2508 - accuracy: 0.4583\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.1752 - accuracy: 0.5417\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.1792 - accuracy: 0.5417\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2217 - accuracy: 0.4844\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 1.2071 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 1.2282 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.1774 - accuracy: 0.5417\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.2537 - accuracy: 0.4531\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.2156 - accuracy: 0.5208\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 1.2483 - accuracy: 0.4583\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 1.2007 - accuracy: 0.5469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ebc0c95f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHAob_P6qpO6",
        "outputId": "f9d611c1-ad71-4a8d-c272-4fa872f6b139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "alexscore = AlexNet.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', alexscore[0])\n",
        "print('Test accuracy:', alexscore[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.3311328887939453\n",
            "Test accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZAcXDv4qtnc",
        "outputId": "803f5dd5-7ed8-40ae-95db-c94e2f0a8ff4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = model.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.00      0.00      0.00         3\n",
            "  class 1(bike)       0.00      0.00      0.00         2\n",
            "class 2(random)       0.50      1.00      0.67         5\n",
            "\n",
            "       accuracy                           0.50        10\n",
            "      macro avg       0.17      0.33      0.22        10\n",
            "   weighted avg       0.25      0.50      0.33        10\n",
            "\n",
            "[[0 0 3]\n",
            " [0 0 2]\n",
            " [0 0 5]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-ZuqHW2L3x"
      },
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA5xkUha1BUo"
      },
      "source": [
        "#vgg16\n",
        "vggmodel = Sequential()\n",
        "vggmodel.add(Conv2D(input_shape=(128,128,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Oa35rl2Q5M"
      },
      "source": [
        "keras.layers.Dropout(0.5)\n",
        "vggmodel.add(Flatten())\n",
        "vggmodel.add(Dense(units=200,activation=\"relu\"))\n",
        "keras.layers.Dropout(0.5)\n",
        "vggmodel.add(Dense(units=200,activation=\"relu\"))\n",
        "keras.layers.Dropout(0.5)\n",
        "vggmodel.add(Dense(units=3, activation=\"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj3OkIly2xbF",
        "outputId": "bab21a80-4753-4cb8-e402-dab2f4d4bec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        }
      },
      "source": [
        "vggmodel.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_97 (Conv2D)           (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_75 (MaxPooling (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_76 (MaxPooling (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_101 (Conv2D)          (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_102 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_103 (Conv2D)          (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_77 (MaxPooling (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_104 (Conv2D)          (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_105 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_106 (Conv2D)          (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_78 (MaxPooling (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_107 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_108 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_109 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_79 (MaxPooling (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_26 (Flatten)         (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_87 (Dense)             (None, 200)               6553800   \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dense_89 (Dense)             (None, 3)                 603       \n",
            "=================================================================\n",
            "Total params: 21,309,291\n",
            "Trainable params: 21,309,291\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-97kUBD_ZfaH"
      },
      "source": [
        "#from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)\n",
        "vggmodel.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGczUBGS24ft",
        "outputId": "3dc2a05c-b0f8-4012-f698-138767b0192f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "vggmodel.compile(optimizer=\"adam\", loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "VGG=vggmodel.fit(train_x,train_y,batch_size = 32,epochs=100,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])\n",
        "VGG"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"conv2d_97_input:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-188-743e2fc9ecce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvggmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mVGG\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvggmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mVGG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_87 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape [None, 8192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VfSOlu5Fd_",
        "outputId": "c7e9742a-2213-45f0-8703-96836a75e412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "vggscore = vggmodel.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', vggscore[0])\n",
        "print('Test accuracy:', vggscore[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 2.089756727218628\n",
            "Test accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xb0R3Ul5OzS",
        "outputId": "da427bc1-89f1-47de-9516-0944cdb43da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = vggmodel.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.67      1.00      0.80         2\n",
            "  class 1(bike)       1.00      1.00      1.00         2\n",
            "class 2(random)       1.00      0.83      0.91         6\n",
            "\n",
            "       accuracy                           0.90        10\n",
            "      macro avg       0.89      0.94      0.90        10\n",
            "   weighted avg       0.93      0.90      0.91        10\n",
            "\n",
            "[[2 0 0]\n",
            " [0 2 0]\n",
            " [1 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEu6Rpr-BrvZ",
        "outputId": "22222774-df71-4b81-ec8f-9dac557e417e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(vgg.history[\"accuracy\"])\n",
        "plt.plot(vgg.history['val_accuracy'])\n",
        "plt.plot(vgg.history['loss'])\n",
        "plt.plot(vgg.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PA5jf1eNZUu",
        "outputId": "1a30cea5-b6b1-4fee-f5bd-a2635d7437bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "#lenet\n",
        "lenet_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='relu', input_shape=train_x[0].shape, padding='same'), #C1\n",
        "    keras.layers.AveragePooling2D(), #S2\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='relu', padding='same'), #C3\n",
        "    keras.layers.AveragePooling2D(), #S4\n",
        "    keras.layers.Flatten(), #Flatten\n",
        "    keras.add(Dropout(0.5))\n",
        "    keras.layers.Dense(120, activation='relu'), #C5\n",
        "    keras.layers.Dense(84, activation='relu'), #F6\n",
        "    keras.add(Dropout(0.5))\n",
        "    keras.layers.Dense(3, activation='softmax') #Output layer\n",
        "])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-64-c60b01be10b4>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    keras.layers.Dense(120, activation='relu'), #C5\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMadyQkS35ei",
        "outputId": "b8977571-f71b-41e0-8f90-db57a1d4e9fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import models, layers\n",
        "import keras\n",
        "#Instantiate an empty model\n",
        "lenet = Sequential()\n",
        "\n",
        "# C1 Convolutional Layer\n",
        "lenet.add(layers.Conv2D(6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(128,128,3), padding='same'))\n",
        "\n",
        "# S2 Pooling Layer\n",
        "lenet.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(1, 1), padding='valid'))\n",
        "\n",
        "# C3 Convolutional Layer\n",
        "lenet.add(layers.Conv2D(16, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
        "\n",
        "# S4 Pooling Layer\n",
        "lenet.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "# C5 Fully Connected Convolutional Layer\n",
        "lenet.add(layers.Conv2D(120, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='valid'))\n",
        "\n",
        "lenet.add(Dropout(0.5))\n",
        "#Flatten the CNN output so that we can connect it with fully connected layers\n",
        "lenet.add(layers.Flatten())\n",
        "\n",
        "# FC6 Fully Connected Layer\n",
        "lenet.add(layers.Dense(84, activation='relu'))\n",
        "lenet.add(Dropout(0.5))\n",
        "\n",
        "#Output Layer with softmax activation\n",
        "lenet.add(layers.Dense(3, activation='softmax'))\n",
        "lenet.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_49 (Conv2D)           (None, 128, 128, 6)       456       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 127, 127, 6)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 123, 123, 16)      2416      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 61, 61, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 57, 57, 120)       48120     \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 57, 57, 120)       0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 389880)            0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 84)                32750004  \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 3)                 255       \n",
            "=================================================================\n",
            "Total params: 32,801,251\n",
            "Trainable params: 32,801,251\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBlH2QRBOelA",
        "outputId": "db62895d-0aeb-4b29-a21a-2caaf0bf6182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"lenet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "#from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)\n",
        "lenet.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "lenetmodel=lenet.fit(train_x,train_y,batch_size = 32,epochs=100,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 5.0518 - accuracy: 0.4125\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.20000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 6s 2s/step - loss: 5.0518 - accuracy: 0.4125 - val_loss: 1.8167 - val_accuracy: 0.2000\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.1760 - accuracy: 0.3750\n",
            "Epoch 00002: val_accuracy improved from 0.20000 to 0.70000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 5s 2s/step - loss: 1.1760 - accuracy: 0.3750 - val_loss: 0.8011 - val_accuracy: 0.7000\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.0275 - accuracy: 0.4750\n",
            "Epoch 00003: val_accuracy improved from 0.70000 to 0.90000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 4s 1s/step - loss: 1.0275 - accuracy: 0.4750 - val_loss: 0.9386 - val_accuracy: 0.9000\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.9150 - accuracy: 0.7625\n",
            "Epoch 00004: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.9150 - accuracy: 0.7625 - val_loss: 0.7550 - val_accuracy: 0.7000\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.7769 - accuracy: 0.6750\n",
            "Epoch 00005: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.7769 - accuracy: 0.6750 - val_loss: 0.5980 - val_accuracy: 0.9000\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.8000\n",
            "Epoch 00006: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.6037 - accuracy: 0.8000 - val_loss: 0.5079 - val_accuracy: 0.9000\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8625\n",
            "Epoch 00007: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.3923 - accuracy: 0.8625 - val_loss: 0.3829 - val_accuracy: 0.9000\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2856 - accuracy: 0.9125\n",
            "Epoch 00008: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2856 - accuracy: 0.9125 - val_loss: 0.3908 - val_accuracy: 0.8000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2405 - accuracy: 0.8875\n",
            "Epoch 00009: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2405 - accuracy: 0.8875 - val_loss: 0.4353 - val_accuracy: 0.8000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9625\n",
            "Epoch 00010: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1757 - accuracy: 0.9625 - val_loss: 0.3090 - val_accuracy: 0.8000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9375\n",
            "Epoch 00011: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.2226 - accuracy: 0.9375 - val_loss: 0.3722 - val_accuracy: 0.8000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.1661 - accuracy: 0.9625\n",
            "Epoch 00012: val_accuracy did not improve from 0.90000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.1661 - accuracy: 0.9625 - val_loss: 0.2641 - val_accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.1624 - accuracy: 0.9375\n",
            "Epoch 00013: val_accuracy improved from 0.90000 to 1.00000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 5s 2s/step - loss: 0.1624 - accuracy: 0.9375 - val_loss: 0.1225 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 1.0000\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.2567 - val_accuracy: 0.9000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9875\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0894 - accuracy: 0.9875 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9750\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0623 - accuracy: 0.9750 - val_loss: 0.1621 - val_accuracy: 0.9000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 1.0000\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 1.0000\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 1.0000\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 1.0000\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 1.0000\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9875\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0235 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0782 - val_accuracy: 0.9000\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9000\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9875\n",
            "Epoch 00025: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0385 - accuracy: 0.9875 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 00026: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0298 - accuracy: 0.9875\n",
            "Epoch 00027: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0298 - accuracy: 0.9875 - val_loss: 0.2587 - val_accuracy: 0.9000\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9875\n",
            "Epoch 00028: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0228 - accuracy: 0.9875 - val_loss: 0.2930 - val_accuracy: 0.9000\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 00029: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9000\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 00030: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.0397 - val_accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0428 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 3s 1s/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0385 - val_accuracy: 1.0000\n",
            "Epoch 00033: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd4Rz9K4O4_i",
        "outputId": "e5004503-df2f-4095-ae35-e852443882fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "lenetscore = lenet.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', lenetscore[0])\n",
        "print('Test accuracy:', lenetscore[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.07908450067043304\n",
            "Test accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ymiRWGO-kY",
        "outputId": "6d0b5600-5b57-43e4-dd52-68161925532e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "lenet_pred = lenet.predict(test_x)\n",
        "y_pred = np.argmax(lenet_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.75      1.00      0.86         3\n",
            "  class 1(bike)       1.00      0.50      0.67         2\n",
            "class 2(random)       1.00      1.00      1.00         5\n",
            "\n",
            "       accuracy                           0.90        10\n",
            "      macro avg       0.92      0.83      0.84        10\n",
            "   weighted avg       0.93      0.90      0.89        10\n",
            "\n",
            "[[3 0 0]\n",
            " [1 1 0]\n",
            " [0 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqsC1L2uNES5",
        "outputId": "98b0d02a-e531-45ba-8983-09572bbc1508",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "!pip install scikit-plot\n",
        "from scikitplot.metrics import plot_roc_curve"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.6/dist-packages (0.3.7)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.6/dist-packages (from scikit-plot) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWvGyjTQKSz",
        "outputId": "481df0d3-b970-4045-8055-654855d12ac0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(lenetmodel.history[\"accuracy\"])\n",
        "#plt.plot(lenetmodel.history['val_accuracy'])\n",
        "plt.plot(lenetmodel.history['loss'])\n",
        "plt.plot(lenetmodel.history['val_loss'])\n",
        "#plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Training vs Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\" Training loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEGCAYAAABvtY4XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5fX48c+ZJZmQZEIgYd93gbDJUgRE1LrvWhVFBf3hr9oqtv1S++3PKl2o2lprbV1xQXFBXKsFtRQVRK2y77IHWQIkINm3mXl+f9ybkECWyTJMZua8X695zcydmTtnJnDy5NznnkeMMSillIo+jnAHoJRSKjQ0wSulVJTSBK+UUlFKE7xSSkUpTfBKKRWlXOEOoKq0tDTTo0ePcIehlFIRY9WqVTnGmPSaHmtRCb5Hjx6sXLky3GEopVTEEJE9tT2mJRqllIpSmuCVUipKaYJXSqko1aJq8EqpU6O8vJx9+/ZRUlIS7lBUkDweD126dMHtdgf9Gk3wSsWgffv2kZycTI8ePRCRcIej6mGM4ciRI+zbt4+ePXsG/Tot0SgVg0pKSmjbtq0m9wghIrRt27bBf3FpglcqRmlyjyyN+XmFNMGLSKaIbBCRtSISkgnuxhgeX7KdpduyQ7F7pZSKWKdiBD/JGDPMGDMyFDsXEZ5dtoulWzXBKxWJxowZw7Bhw+jWrRvp6ekMGzaMYcOGkZmZWe9rDxw4wDXXXFPv8y666CKOHTvW5FgzMzMZPHhwk/dzqkTFQVavx0VeSXm4w1BKNcLXX38NwNy5c1m5ciX/+Mc/qj3u8/lwuWpOVZ06deKtt96q9z0WLVrU9EAjUKhH8Ab4t4isEpHba3qCiNwuIitFZGV2duNG4d4EN3nFmuCVihazZs3ipptuYty4cdx0001kZmYyYcIERowYwYgRI/jyyy+B6iPquXPnctVVV3HBBRfQt29ffvnLX1bur0ePHuTk5JCZmclpp53G9OnTGTRoEOeddx7FxcUArFixgiFDhjBs2DBmzpxZ70i9pKSEadOmkZGRwfDhw/n0008B2LRpE6NHj2bYsGEMGTKE7du3U1hYyMUXX8zQoUMZPHgwb7zxRii+tpOEegQ/3hizX0TaAYtF5FtjzLKqTzDGPAs8CzBy5MhGrR/o9bjJ1QSvVKP89oNNbD6Q16z7HNjJywOXDmrSPjZv3szy5ctJSEigqKiIxYsX4/F42L59O5MnT66xb9XatWtZs2YN8fHx9O/fn7vuuouuXbtWe8727dt5/fXXmTNnDtdeey1vv/02U6ZMYdq0acyZM4exY8fyq1/9qt74nnjiCUSEDRs28O2333Leeeexbds2nn76aWbMmMGNN95IWVkZfr+fRYsW0alTJxYuXAhAbm5uk76bYIV0BG+M2W9fHwbeBUaH4n28CS7ySnyh2LVSKkwuu+wyEhISAOvErOnTp5ORkcGPfvQjNm/eXONrzjnnHFJSUvB4PAwcOJA9e07uw9WzZ0+GDRsGwOmnn05mZibHjh0jPz+fsWPHAnDDDTfUG9/y5cuZMmUKAAMGDKB79+5s27aNsWPH8sc//pGHH36YPXv2kJCQQEZGBosXL+bee+/l888/JyUlpVHfSUOFbAQvIomAwxiTb98+D/hdKN7L63GzpTg/FLtWKuo1daQdKomJiZW3//rXv9K+fXvWrVtHIBDA4/HU+Jr4+PjK206nE5/v5IHfic+pKNE0lxtuuIExY8awcOFCLrroIp555hnOPvtsVq9ezaJFi7jvvvs455xzuP/++5v1fWsSyhF8e2C5iKwDvgEWGmM+CsUbeRPcepBVqSiWm5tLx44dcTgczJs3D7/f36z7b926NcnJyZUHfOfPn1/vayZMmMCrr74KwLZt2/juu+/o378/u3btolevXtx9991cfvnlrF+/ngMHDtCqVSumTJnCzJkzWb16dbPGX5uQjeCNMbuAoaHaf1Vej4uCUh+BgMHh0JM3lIo2d955J1dffTUvv/wyF1xwQbXRfXN5/vnnmT59Og6Hg4kTJ9ZbRrnzzju54447yMjIwOVyMXfuXOLj41mwYAHz5s3D7XbToUMHfv3rX7NixQpmzpyJw+HA7Xbz1FNPNXv8NRFjGnVcMyRGjhxpGrPgx3Of7+IPC7ew7oHzSEkIvhGPUrFqy5YtnHbaaeEOo0UpKCggKSkJgIceeoisrCz+9re/hTmq6mr6uYnIqtrOM4qSefBWUs8rLtcEr5RqlIULF/Lggw/i8/no3r07c+fODXdITRYdCT7B+hhah1dKNdZ1113HddddF+4wmlVUNBs7PoLXqZJKKVUhOhK8XZbREbxSSh0XHQm+Sg1eKaWUJToSfGUNXks0SilVISoSfLKO4JWKKJMmTeLjjz+utu2xxx7jjjvuqPU1Z511VmX/mdra/86aNYtHHnmkzvd+7733qrU6uP/++/nPf/7TkPBr9Nlnn3HJJZc0eT/NKSoSvNMhJMdry2ClIsXkyZNPOlt0/vz5TJ48OajXL1q0iNatWzfqvU9M8L/73e8499xzG7Wvli4qEjxUtAzWEo1SkeCaa65h4cKFlJWVAVbb3wMHDjBhwgTuuOMORo4cyaBBg3jggQdqfH1F+1+A2bNn069fP8aPH8/WrVsrnzNnzhxGjRrF0KFDufrqqykqKuLLL7/k/fffZ+bMmQwbNoydO3cyderUyp7yS5YsYfjw4WRkZHDrrbdSWlpa+X4PPPAAI0aMICMjg2+//Tboz/r666+TkZHB4MGDuffeewHw+/1MnTqVwYMHk5GRwV//+lcAHn/8cQYOHMiQIUO4/vrrG/itniwq5sEDJOuiH0o1zoe/goMbmnefHTLgwodqfbhNmzaMHj2aDz/8kMsvv5z58+dz7bXXIiLMnj2bNm3a4Pf7Oeecc1i/fj1DhgypcT+rVq1i/vz5rF27Fp/Px4gRIzj99NMBuOqqq5g+fToA9913H88//zx33XUXl112GZdccslJK0GVlJQwdepUlixZQr9+/bj55pt56qmnuOeeewBIS0tj9erVPPnkkzzyyCM899xz9X4NBw4c4N5772XVqlWkpqZy3nnn8d5779G1a1f279/Pxo0bASrLTQ899BC7d+8mPj6+WVagirIRvCZ4pSJF1TJN1fLMggULGDFiBMOHD2fTpk21tgYG+Pzzz7nyyitp1aoVXq+Xyy67rPKxjRs3MmHCBDIyMnj11VfZtGlTnfFs3bqVnj170q9fPwBuueUWli07vnzFVVddBRxvMRyMFStWcNZZZ5Geno7L5eLGG29k2bJl9OrVi127dnHXXXfx0Ucf4fV6ARgyZAg33ngjr7zySq2rWDVE1IzgvR43+481b9tPpWJCHSPtULr88sv52c9+xurVqykqKuL0009n9+7dPPLII6xYsYLU1FSmTp1KSUlJo/Y/depU3nvvPYYOHcrcuXP57LPPmhRvRZvh2toQN0Rqairr1q3j448/5umnn2bBggW88MILLFy4kGXLlvHBBx8we/ZsNmzY0KREH0UjeJeO4JWKIElJSUyaNIlbb721cvSel5dHYmIiKSkpHDp0iA8//LDOfZx55pm89957FBcXk5+fzwcffFD5WH5+Ph07dqS8vLyyrS9AcnIy+fknrx/Rv39/MjMz2bFjBwDz5s1j4sSJTfqMo0ePZunSpeTk5OD3+3n99deZOHEiOTk5BAIBrr76av7whz+wevVqAoEAe/fuZdKkSTz88MPk5uZSUFDQpPePqhG81uCViiyTJ0/myiuvrCzVDB06lOHDhzNgwAC6du3KuHHj6nz9iBEjuO666xg6dCjt2rVj1KhRlY/9/ve/Z8yYMaSnpzNmzJjKpH799dczffp0Hn/88WoLdns8Hl588UV+9KMf4fP5GDVqFD/+8Y8b9HmWLFlCly5dKu+/+eabPPTQQ0yaNAljDBdffDGXX34569atY9q0aQQCAQAefPBB/H4/U6ZMITc3F2MMd999d6NnClWIinbBAI8u3sbfP9nOztkXaU94peqh7YIjU0PbBUdPicbjwhjIL9WpkkopBdGU4BP0bFallKoqehK8RztKKtUQLak8q+rXmJ9X9CR4u+FYro7glaqXx+PhyJEjmuQjhDGGI0eO4PF4GvS6qJpFA7roh1LB6NKlC/v27SM7OzvcoaggeTyeajN0ghE1CT5FF/1QKmhut5uePXuGOwwVYtFTotGWwUopVU3UJPgkjy76oZRSVUVNgq/sCa8jeKWUAqIowYPdUVJr8EopBURZgk/2uHQWjVJK2RqU4EXEISLeUAXTVDqCV0qp4+pN8CLymoh4RSQR2AhsFpGZoQ+t4VJ00Q+llKoUzAh+oDEmD7gC+BDoCdwU0qgayetxk6+zaJRSCgguwbtFxI2V4N83xpQDQZ/fLCJOEVkjIv9qbJDB0kU/lFLquGAS/DNAJpAILBOR7kBeA95jBrCl4aE1nNfjJr/Uhz+g/TWUUqreBG+MedwY09kYc5Gx7AEmBbNzEekCXAzUv/x4M6hoGVygZRqllArqIOsM+yCriMjzIrIaODvI/T8G/BII1LH/20VkpYisbGrjI2/l2axaplFKqWBKNLfaB1nPA1KxDrDWuwy7iFwCHDbGrKrrecaYZ40xI40xI9PT04OJuVYVI3htGayUUsEl+IoFTi8C5hljNlXZVpdxwGUikgnMB84WkVcaFWWQdNEPpZQ6LpgEv0pE/o2V4D8WkWTqKLlUMMb8rzGmizGmB3A98IkxZkqToq1HxaIfejarUkoF1w/+NmAYsMsYUyQibYFpoQ2rcXQEr5RSx9Wb4I0xAXs2zA0iArDUGPNBQ97EGPMZ8FljAmwIXXhbKaWOC2YWzUNYc9k325e7ReSPoQ6sMZLjXYhoT3illILgSjQXAcOMMQEAEXkJWAP8OpSBNYbDISRpT3illAKC7ybZusrtlFAE0ly8Hu0oqZRSENwI/kFgjYh8ijU98kzgVyGNqgm8CW6dRaOUUgR3kPV1EfkMGGVvuhfoHsqgmsLr0RKNUkpBcCN4jDFZwPsV90XkG6BbqIJqCm+Cm71Hi8IdhlJKhV1jl+wL5kzWsPB6dNEPpZSCxif4FtuP15vg0mmSSilFHSUaEfmAmhO5AG1DFlETeT1uCkp9+PwBXM6oWlNcKaUapK4a/CONfCysKnvCl/po3SouzNEopVT41JrgjTFLT2UgzSWlsl2BJnilVGyLuhqGLvqhlFKW6Evw2nBMKaWAaEzw2jJYKaWAIE50EpF+wEyss1crn2+MCXZd1lNKF/1QSilLMGeyvgk8DcwB/KENp+kqSzQ6gldKxbhgErzPGPNUyCNpJklxdk94rcErpWJcMDX4D0TkThHpKCJtKi4hj6yRHA4hOV7PZlVKqWBG8LfY1zOrbDNAr+YPp3lYLYN1BK+Uim3BtAvueSoCaU666IdSSgU3i8YN3IG10AdYi2c/Y4xpsRnUm+DSWTRKqZgXTA3+KeB04En7crq9rcXSEbxSSgVXgx9ljBla5f4nIrIuVAE1B63BK6VUcCN4v4j0rrgjIr1o4fPhrRG8lmiUUrEtmBH8TOBTEdmF1Qu+OzAtpFE1kTfBpT3hlVIxL5hZNEtEpC/Q39601RhTGtqwmqaiH432hFdKxbK6VnQ62xjziYhcdcJDfUQEY8w7IY6t0bzaE14ppeocwU8EPgEureExA7TcBG/3hM/VA61KqRhW14pOD9g3f2eM2V31MRFp0Sc/acMxpZQKbhbN2zVse6u5A2lOlT3hdQSvlIphddXgBwCDgJQT6vBewFPfjkXEAywD4u33eavKXwUhVdkTXkfwSqkYVlcNvj9wCdCa6nX4fGB6EPsuBc42xhTY7Q6Wi8iHxpj/NjraIFVdeFsppWJVXTX4fwL/FJGxxpivGrpjY4wBCuy7bvtiGhVlAyXGuXCIjuCVUrEtmBOd1ojIT7DKNZWlGWPMrfW9UEScwCqgD/CEMebrxgbaEA6HkOzRdgVKqdgWzEHWeUAH4HxgKdAFq0xTL2OM3xgzzH7NaBEZfOJzROR2EVkpIiuzs7ODj7we3gRd9EMpFduCSfB9jDG/AQqNMS8BFwNjGvImxphjwKfABTU89qwxZqQxZmR6enpDdlsnr47glVIxLpgEX5Elj9kj8BSgXX0vEpF0EWlt304Afgh829hAG0pbBiulYl0wNfhnRSQV+A3wPpAE3B/E6zoCL9l1eAewwBjzr0ZH2kDeBBeZOUWn6u2UUqrFCabZ2HP2zaU0YB1WY8x6YHgj42oyHcErpWJdXSc6/byuFxpjHm3+cJqPLvqhlIp1dY3gk+3r/sAorPIMWCc9fRPKoJqD1+OmsMyvPeGVUjGrrhOdfgsgIsuAEcaYfPv+LGDhKYmuCSraFeSX+EhN1JbBSqnYE8zQtj1QVuV+mb2tRatsOKZ1eKVUjApmFs3LwDci8q59/wpgbsgiaiZe7UejlIpxwcyimS0iHwIT7E3TjDFrQhtW01Us+qEjeKVUrKprFo3XGJMnIm2ATPtS8VgbY8zR0IfXeMdH8JrglVKxqa4R/GtY7YJXUb0LpNj3g54THw66qpNSKtbVNYvmEvu6RS/PV5vKEo3W4JVSMaquEs2Iul5ojFnd/OE0H+0Jr5SKdXWVaP5Sx2MGOLuZY2lW2hNeKRXr6irRTDqVgYSC9oRXSsWyYObBY7cJHkj1FZ1eDlVQzcXrcZOrI3ilVIyqN8GLyAPAWVgJfhFwIbAc6wSoFi1FG44ppWJYMK0KrgHOAQ4aY6YBQ7EW/WjxtGWwUiqWBZPgi40xAcAnIl7gMNA1tGE1D2+CS6dJKqViVjA1+JX20ntzsE56KgC+CmlUzURH8EqpWFbXPPgngNeMMXfam54WkY8Ar71aU4vnTXBTVOan3B/ArT3hlVIxpq4R/DbgERHpCCwAXo+EJmNVVZzNml/io432hFdKxZhah7XGmL8ZY8YCE4EjwAsi8q2IPCAi/U5ZhE2gDceUUrGs3rqFMWaPMeZhY8xwYDJWP/gtIY+sGeiiH0qpWFZvghcRl4hcKiKvAh8CW4GrQh5ZM9BFP5RSsayug6w/xBqxX4S1yPZ84HZjTOEpiq3JKtZl1RG8UioW1XWQ9X+xesL/whjz/SmKp1lVlmi0Bq+UikF1NRtr0d0ig6GLfiilYllUTw5PjHNaPeG1Bq+UikFRneBFBG+Cns2qlIpNwcyiSRQRh327n4hcJiLu0IfWPLy66IdSKkYFM4JfBnhEpDPwb+AmYG4og2pOuuiHUipWBZPgxRhThDX3/UljzI+AQaENq/noCF4pFauCSvAiMha4EVhob3OGLqTmpR0llVKxKpgEPwNrTvy7xphNItIL+LS+F4lIVxH5VEQ2i8gmEZnR1GAbQ3vCK6ViVTD94AuMMZdV3DHG7ALuDuJ1PqyTpFaLSDKwSkQWG2M2NzLWRtERvFIqVgUzgv+LiGwRkd/bi28HxRiTZYxZbd/Ox2pQ1rmRcTZa1Z7wSikVS4LpJjkJmARkA8+IyAYRua8hbyIiPYDhwNc1PHa7iKwUkZXZ2dkN2W1QUuyzWfN1Jo1SKsYEdaKTMeagMeZx4MfAWuD+YN9ARJKAt4F7jDF5Nez7WWPMSGPMyPT09GB3G7TKhmM6k0YpFWOCOdHpNBGZJSIbgL8DXwJdgtm5fULU28Crxph3mhRpI1U0HMvVBK+UijHBHGR9AatV8PnGmAPB7lhEBHge2GKMebSR8TWZNhxTSsWqehO8vWxfY4zDOut1g4istbf92hizqJH7a5TjLYO1Bq+Uii3BjOAbxRizHJBQ7b+GNwQ5+e100Q+lVKyK/G6SvlJ45kz48vEaH9ZFP5RSsSryE7wrHspLIHN5jQ+3inPidIiO4JVSMafeEo2IfACYEzbnAiuBZ4wxJaEIrEG6j4WN70LAD47qbXJEBK9H2xUopWJPMCP4XUABMMe+5AH5QD/7fvh1OwNKc+FwzV0QdNEPpVQsCuYg6xnGmFFV7n8gIiuMMaNEZFOoAmuQ7mdY13u+hA4ZJz2sLYOVUrEomBF8koh0q7hj306y75aFJKqGat0VUrpaCb4GuuiHUioWBTOC/wWwXER2Yk177AncKSKJwEuhDK5Buo2F3UtrnC7p9bg5nFcQpsCUUio8gjnRaZGI9AUG2Ju2Vjmw+ljIImuo7mNhwwI4ugva9q72kLYMVkrFomBPdDod6GE/f6iIYIx5OWRRNUa3KnX4ExO8LvqhlIpBwTQbmwc8AowHRtmXkSGOq+HS+0OrtvDdVyc95PW4KS73U+bTnvBKqdgRzAh+JDDQGHPiXPiWRcSqw9dwoNVb2RO+nLZJ8ac6MqWUCotgZtFsBDqEOpBm0W0sfL8b8g9W23y8H42WaZRSsSOYEXwasFlEvgFKKzZWXae1xehuN77c8yUMvqpys/ajUUrFomAS/KxQB9FsOgwFd+LJCV57wiulYlAw0ySXnopAmoXTBV1Hn3SgVXvCK6ViUa01eBFZbl/ni0helUu+iJy0tmqL0f0MOLQJio9VbkrREbxSKgbVmuCNMePt62RjjLfKJdkY4z11ITZQt7GAgb1fV27ShbeVUrEoqH7wIuIUkU4i0q3iEurAGq3LSHC4Yc8XlZsS3E5c2hNeKRVjgukHfxfwAHAIqDhTyABDQhhX47kToPMI2HO8Di8iVstgrcErpWJIMLNoZgD9jTFHQh1Ms+k2Fr56AsqLrYQPeD0ucrVEo5SKIcGUaPZireAUObqfAYFy2LeycpMu+qGUijXBjOB3AZ+JyEKqn+j0aMiiaqquYwCx5sP3nADooh9KqdgTTIL/zr7E2ZeWL6E1tB8M3x3vS+NNcHEwL/zLxyql1KkSzIlOvz0VgTS77mNhzavg94HTpSN4pVTMqetEp8fs6w9E5P0TL6cuxEbqNhbKC+HgOkBr8Eqp2FPXCH6eff3IqQik2VUuxP0VdD4dr8dFSXmATQdyGdQpJbyxKaXUKVDXmayr7OulNV1OXYiNlNwBUntW9oc/d2B72ibGcdk/vuD3/9pMQanOiVdKRbdgVnTqKyJvichmEdlVcTkVwTVZ93FW47FAgAEdvCz5xUSuH9WVF77YzTl/+YyF67No6euYKKVUYwUzD/5F4CnAB0wCXgZeCWVQzab7WCg+CjnbAGjdKo7ZV2bwzh1nkJYUz09eW83NL3zD7pzCMAeqlFLNL5gEn2CMWQKIMWaPMWYWcHFow2om3ewFQL6rvozf8G6p/PMn45h16UDWfneM8x9bxl8Xb6Ok3B+GIJVSKjSCSfClIuIAtovIT0XkSiCpvheJyAsiclhENjY5ysZq0wuS2te4TqvL6WDquJ4s+cVELhjUgb8t2c75jy3js62HwxCoUko1v2AS/AygFXA3cDowBbgliNfNBS5odGTNQcSaTbPnq1qf0s7r4fHJw3nltjE4RZj64gpufuEbvtyZo/V5pVREqzPBi4gTuM4YU2CM2WeMmWaMudoY89/6dmyMWQYcba5AG63bGZC3D459V+fTxvdN48N7JvCrCwew+UAuN8z5miue+IJFG7LwBzTRK6UiT10nOrmMMX5gfCgDEJHbRWSliKzMzs5u/jeoXIi79lF8hXiXkx9P7M3ye89m9pWDyS0u585XV3Puo0t57evvtEavlIooUlsZQkRWG2NGiMhTQGfgTaByuokx5p16dy7SA/iXMWZwMMGMHDnSrFy5sv4nNkTADw/3hEFXwGWP1/1cvw82vQvtB0H7gfgDho83HeTppTtZvy+XtKR4po3rwZQfdK9cBlAppcJJRFYZY0bW9FgwzcY8wBHgbKyFPsS+rjfBtwgOJ3Qbc9JC3CfZ8R/4+D7I3gIuD1z4MM4Rt3BRRkcuHNyBr3Yd4emlu/jzx1t58tMd3PiD7tx5Vm9at4qM/mtKqdhTV4JvJyI/BzZyPLFXiKyidPczYPu/oTAHEtOqP5a9FT7+f7BjsXXm61VzYO1r8MEMa/bNxY8i8Umc0TuNM3qnsflAHs8s28lzn+/ijRV7uefcvkz5QXfczqBWP1RKqVOmrqzkxJoOmQQkV7ldcamTiLwOfAX0F5F9InJb08NtpG52X5qqo/jCI7Dwf+DJsbD3GzjvD/CTr2HItTDlbZj0/2D9AphzNhzeUvmygZ28/O364SyaMYGMzin89oPNnP/YMj759pDOulFKtSj11uBPZTAhqcED+Mrgoa4w8jY4dxZ88yws/ROUFcDIW+GsX508sgfYtRTe/j/W8y7+Cwy7odrDxhg++fYwsxduYVdOIRP6pnHfxQPp3yG5+T+DUkrVoK4afF0Jfo0xZnhIIztByBI8wIsXw7E94HTD0V3Q54fWqL3dgLpfl3/QSvKZn8PwKXDhnyGuVbWnlPkCvPLfPTz2n20UlPqYPLobP/9hP9omxYfmsyillK2uBF9XieacEMUTHj3GQ+5ecMZZJZgpb9Wf3MHqSnnTe3DmTFjzCjx3LuRsr/aUOJeDW8f3ZOnMSdw8tgfzV+zlrD9/xrPLdlLq06mVSqnwqHUEHw4hHcGX5kPmF9DnXHAGM3moBtv/A+9MB38ZXPo3yLimxqftOJzP7IVb+HRrNgM6JPP45OH0a69lG6VU82vsCD66xCdD/wsan9wB+p4LP15urff69m2w4GbIP3TS0/q0S+bFaaN57uaR5BSUcunfl/PyV5l6EFYpdUrFToJvLimdYeq/4JwHYOtH8MRoq3RTQ/I+d2B7PpxxJmN7t+X+f27itpdWklNQGoaglVKxSBN8YzjdMOHncMcX0G4g/PMnMO8KOLr7pKemJ8fz4tRRzLp0IMt35HDBY59rx0ql1CmhCb4p0vrC1IVw8aOwbxU8dQZ89YTVHqEKEWHquJ588NPxtE2MY+qLK5j1/ibtbaOUCilN8E3lcMCo2+An/4WeZ8LHv4bnz4NDm096av8Oyfzzp+OYNq4Hc7/M5PJ/fMHWg/lhCFopFQs0wTeXlC4weT5c/Tx8nwnPnAmf/hF81WvuHreTBy4dxNxpozhSWMal/1jO3C926wFYpVSzi51pkqdS4RH4+H9h/RuQ0MaaTjl0MnQabi1CYsspKOXet9az5NvDXD+qK7+/YrD2tPfn1OsAABOeSURBVFFKNUijzmQNh6hJ8BV2fw4rX4BvF4K/FNIHWIl+yLXg7QRY7Q4eXbyNv3+ygzP7pfPEDcNJ9mgrYqVUcDTBh1vxMavP/LrXYe/XIA7odRYMvQEGXAxxrXhjxXf8+t2N9G2XxIvTRtExJSHcUSulIoAm+JbkyE5YN9+65H4Hcckw+CoY/zOW5SRx56urSYp38eK0UZzW0RvuaJVSLZwm+JYoEIA9X1ij+o1vQ8AHw6ewfcAd3PTmfgpKfTx54wjO7Jce7kiVUi2YtipoiRwO6DkBrngSZqyzWhmvfY2+8yewZOBChrQuYdrcFSxYsTfckSqlIpSO4FuSY3th2Z9hzSsYZxyLEi7lvuyzuXHSCH5xXj9EpP591MTvgyM74NBGOLjBWsCk3QA4YwYktm3ez6CUOqW0RBNpjuyEpX/CrH+DMoeHZ8rOJ+u025h13TjiXc7aX2cMFH8PhzbZyXwjHNoAh7+1ZvEAONzQphcc2Q7uVjD2J9bFk3JqPptSqllpgo9Uh7/FfPYgsvk98kwrtjt70SXZQZrH4PSXga/YOpHKVwLlJceTeIVWadBhsNX9skOGdZ3WD1xx1lq0n86Gzf8ET2sYfw+Mvh3iEoOPz++Dg+sgqb11opdS6pTTBB/pstZz6MMHOZqVSU6JA78jjvQ2renRvg2JiUng8oArHlwJEJ8E7U6zknlS+2onVtW873XwyR+sRckT28GZ/wOnT7X2d6JAAA5vht1LYfcyq79+Wb417XPg5TD2p9Clxn9nSqkQ0QQfRdbtPcaLX+zmX+uzCBjDDwe257bxvRjVI7XxNXqA7/5rJfrMzyGlK0z8pTVP/9geK5nvXmqduFWUYz2/TW/oNdFaKStrHaycC6W50HWMVfIZcAk46ignKaWahSb4KHQwt4R5/83k1a+/41hROYM7e7ltfE8uzuhEnKuRk6OMgV2fwSe/h/2rwJ0I5YXWY8kdoedEK6n3PPPkkkxpAax9Ff77pNWLp3V3+MEd1jq28bqalQqh0nwoOGwdW2rKICdCaYKPYsVlft5ds58XvtjNjsMFpLZyM6RLawZ28nJaRy8DO3rpmZaI09GAf/jGwNYPYesi6DjUOuu2bZ/g/vME/NbrvnoCvvsK4r0w4mYY82No3bWxH1PFuuJjcHSXfdltX++0rguzref0uxCufAoSUsMb6ymmCT4GGGNYtj2H99ceYHNWHjsO51Put362HreD/h28DOyYzMCOVuIf1CmFhLgQl1D2r4KvnrTaNIhYB3En3gsJrRu3v0AANiywfoGMuAX6RNe68OoEgQD8535Y8yoUH63+mLezNWJv09O69pVaU4y9neG6edbAJEZogo9BZb4AOw4XsDkrjy1ZeWw+kMeWg3kcKyoHIM7pYGSPVMb1SWN8nzQGd05p0Ci/3B9g+yFr/63inIzsnko7r6fmJ1fM71/9MrRqC+fcb5VuGlKj3/UZ/Ps3cHC9Nb2zvMiq858/G1J7BL8fFRn85fDeHbDhTesAfueRViJv29v6ebtr6NW09xtYcAsUHYGLH7H+cowBmuAVYI3ys3JL2HQgj292H2H5jiNsycoDICXBzRm92zK+r5Xwu7c9Pl2yuMzPloN5bDqQx6b9uWw6kMfWg/mU+QPV9t+tTStG9khlZPc2jOqRSu/0JBxVf2kcWAsf3gt7/2uNsC78E3T7Qd1BH9oMi++HHYshpZv1y+G0S6xa/7JHwARg/M9g3Iya/9OryFNWBG9Ohe0fw7mzrJ9vsApz4O3brAHB8Clw0SNR/+9CE7yqVXZ+KV/uzOGLHTks357DgdwSALq2SWBgRy+7sgvZmV1AwP5nktrKzaBOKQzqbJV5BnXykldczsrM71m55ygrM7/nSGEZYP3SGNk9ldN7pDK0S2sS4py4BFJ3f0CHr2fjLjxIQb8ryRt3H9K6M06H0DYx3vpLIv+gNU9/zStWQ7Yz/8cq8bir/JWQu88a1W96B1p3g/P/aI3qG3KgrazQ+osgBg/OtUglufDa9dbxm0v+CiOnNXwfAT989qD1V2OHDLj2ZWv0H6U0waugGGPYnVPIFzty+Hx7DtsO5dOnXRIDO6UwuJOXQZ1T6JTiqXM6pjGGzCNFrMg8yqrM71mx5yi7sgtPel4CJdzpep/bnQvx4+AJ3+U857+ILl43f+68jOH75iH+chg9Hc6cCa3a1B747mXWXwaHN0Pvs+GChyG938nPKzhs/RVxYI11yVoL+VkQn3K8lnviJamdJv9TpSAbXrnKaqVx1TMw+Oqm7W/bx/DO7dakgSufslpzRyFN8CqsjhSU8q1d0vH7DX5j8AcMvoAhPn8Pgzb+mS4Hl5Cf0BlfaRGpge/5mB+wZ9hMrjhnPO2Sa6ntV+X3wYrnrGUSywutKZo9z4KsNXZSXwt5++wni7Vgeqfh1nX+oeMzNI59B6bKYujuRCvRp/eHziOs13Qc2rAzflX9ju2FeVdA7n647hXoe27z7Pf7TFhws3Wuxrh74OzfgNPVPPtuITTBq5Zv56ew5HcQl8i2jJ/z2LcpfLTxIC6Hg6tGdOb/TOhFn3ZJ9e+nIBv/4gdwrnu1cpNp2wfpOMxKzp2GQ8chtc/N95dbSb5yKp49He/QJsjbbz1HHJBWJeF3GgHtB1UvH6ng5WyHl6+w5rPf8AZ0H9u8+y8vgY/uhVVzod0gGHAR9JoEXUZZbTsinCZ4FZEycwp5bvku3ly5j1JfgHNPa8+PJ/ZiZA+rXJNbXM7O7AJ2HC5gZ3YBOw8XsDO7kO+OFtHH7KGN5LMx0JNAXDIdUjx0ap1AxxQPHVIS6JTioWPrBDp4PSTGO2kV56JVnJN4l6P2ElT+Ibu8sxr2r7aui45YjzncVofOlG6Q3ME6MezE61ZtwlfuKS+2SlSFOVB42L6dbV0qbpcVAsYqaVS75vh9hwNSe0K7gVZLjHYDrb9wGjsqPrDWKsuIA6a8Y/3yDZX1C+CbObB/pXVwPi7JOhO799lWwk/rG5HluLAleBG5APgb4ASeM8Y8VNfzNcGrmhwpKOWlr/bw8leZHCsqp0+7JHKLy8nOP95cze0UeqYl0js9iT7tkuidnoTTIWTlFpOVW0LWsRKy8krIOlZMdkEptf2zdwi0inOREOekVZyTBLd13SYxjg4pHjqmJNCptX3t9dCebOIPr7MS/qGNkJdl1fVPnLcN4IyrIfl3rH7f27Hmvy6MseZ6lxfZzeWKrdsledYvmcrL0RPu25eygpo/cLwXEtOsPkTxSYDYSa6Wa3+51Xr66C7szG99rrT+0O40ytr2JzuhFyWtOtE+NYmkhARwuMDptp5Xcdvhhn0r4PXrrU6mN70HaX2C/jfRJMXHrJYcOz+FnZ/A97ut7d7O0HuSdca2J8VahCfgt0p2Af8Jt33WLwljzyQ76ZeiOf5Y1c/vdFe5XfF9xFkH+ruc3qiPE5YELyJOYBvwQ2AfsAKYbIzZXNtrNMGruhSV+Xhz5T4Wbz5EhxRPZSLv0y6JrqkJuJzBtWgo8wU4nF9CVm4Jh/JKKCr1U1Tmo6jcb9/2U1zuo6jMb198HCkoIyu3hNzi8pP2l5YUR8eUBNp7PSR7rF8OyU4f6RyjLd+T6j9Cii+H5PIjJJUexlNymLjiw8QVH8JVfnLi9bkSKY9vgxg/Dn8xTl8JDn8JQv3/V8sdCRS5W1Pkak2BI4U8h5cCh5fyhDQkMQ2ntwPxrduT1KYDyW070aZ1Csnxrnr7GBljHTMpKfeTlVvCgewjFOzfQuDQZhK+30pqwU46l2fSkZygfgaVn7VNX3ac/wpZtCE7v5ScglKy849fcgpKKS7zE+dyEOdyEO9yWredFfePb0+Kd5LscZPscZHscZPkcZHsceG17yd7XLgcDkrK/fYlQHG5H77PJHH/56RmLSft8FfE+fIb9BmaQyCxHY6Z2xv12nAl+LHALGPM+fb9/wUwxjxY22s0wauWrqjMV/kXwYHcYrKOlXAwr5gDx6xfFoVlPoorfzH4691fIsW0k2O0l+9pz1HrWo7RVnIpNy5KiKOYeIqJo9TEUWzfL7FvF5LAUZPMUZPM9yRTilVTjnc58Litv0BcTiG3uJz8El+NMcQ5HbRNiiPB7aTMH8DnN5T7A/bF4AsEKs+KPum1LgddUhPoktqKLqkJ9Er20d9xgFalOXyfX8ixgkKOFRSTV1hEQVExEvDhwo8LP34cvOE/i++pvvZwUryL9OR40pPiSU+OJyHOSZkvQJkvQKnPT5k/UOX+8ev8knIKSn2VU3obw0GAfrKPOMrx4yCAAx9OAgj+itvGYT8mGBxYY3apcn38AuDEjxs/bny4xWddV9zHR5z4SE6I59nfzGhUzHUl+FAeTu4MVF1vbh8w5sQnicjtwO0A3bp1C2E4SjVdqzgXvdOtvxzqEwgYSnz2XwR2wi8s8+G3M5BQteQriEDFXREhmGqw0yEk2KWkioQe73JUP8HMVurzc7SwjCMFZeQUlB6/XVhKTn4ZJT4/8U4HLqfgdjrsS/XbcS4HHVIS7KSeQFpifA3vNbzW7yO7oJS9R4vY+30RWbkl/MLjJs1O5O2S40lLim9SCw1jDEVlfvJLfOSXlJNnX1v3ffgCgcrv6fi19cvQ43aSEOckzunAFwhQUm79QikpD1Qb9Zf6/JSWByj1BzD2jLCAsT5fwFizxIwBf8B6zCHWz9Yh9s9VwCFi3bd/7q3iQpOKwz5fyBjzLPAsWCP4MIejVLNxOMQ+eBv2/2YAxLucdExJoGNKeM7sdDiE9l4P7b2eygPlzU1ESIx3kRjvokOKzmoK5aLb+4Gq7QO72NuUUkqdAqFM8CuAviLSU0TigOuB90P4fkoppaoI2d+OxhifiPwU+BhrmuQLxphNoXo/pZRS1YW0OGiMWQQsCuV7KKWUqlkoSzRKKaXCSBO8UkpFKU3wSikVpTTBK6VUlGpR3SRFJBvY08iXp0EDG2G0HJEcO0R2/JEcO2j84dRSYu9ujEmv6YEWleCbQkRW1taPoaWL5NghsuOP5NhB4w+nSIhdSzRKKRWlNMErpVSUiqYE/2y4A2iCSI4dIjv+SI4dNP5wavGxR00NXimlVHXRNIJXSilVhSZ4pZSKUhGf4EXkAhHZKiI7RORX4Y6noUQkU0Q2iMhaEWnx6xWKyAsiclhENlbZ1kZEFovIdvs6NZwx1qaW2GeJyH77+18rIheFM8baiEhXEflURDaLyCYRmWFvj5Tvvrb4I+X794jINyKyzo7/t/b2niLytZ1/3rBbo7cYEV2Db8zC3i2NiGQCI40xLeGEiXqJyJlAAfCyMWawve1PwFFjzEP2L9lUY8y94YyzJrXEPgsoMMY8Es7Y6iMiHYGOxpjVIpIMrAKuAKYSGd99bfFfS2R8/wIkGmMKRMQNLAdmAD8H3jHGzBeRp4F1xpinwhlrVZE+gh8N7DDG7DLGlAHzgcvDHFNUM8YsA46esPly4CX79ktY/3FbnFpijwjGmCxjzGr7dj6wBWvd40j57muLPyIYS4F9121fDHA28Ja9vcV9/5Ge4Gta2Dti/tHYDPBvEVllL0AeidobY7Ls2weB9uEMphF+KiLr7RJOiyxxVCUiPbBWtv6aCPzuT4gfIuT7FxGniKwFDgOLgZ3AMWOMz35Ki8s/kZ7go8F4Y8wI4ELgJ3YZIWIZq+YXSXW/p4DewDAgC/hLeMOpm4gkAW8D9xhj8qo+FgnffQ3xR8z3b4zxG2OGYa0vPRoYEOaQ6hXpCT7iF/Y2xuy3rw8D72L9w4k0h+waa0Wt9XCY4wmaMeaQ/R83AMyhBX//du33beBVY8w79uaI+e5rij+Svv8KxphjwKfAWKC1iFSsjNfi8k+kJ/iIXthbRBLtA06ISCJwHrCx7le1SO8Dt9i3bwH+GcZYGqQiOdqupIV+//ZBvueBLcaYR6s8FBHffW3xR9D3ny4ire3bCVgTO7ZgJfpr7Ke1uO8/omfRANjTqh7j+MLes8McUtBEpBfWqB2s9XFfa+nxi8jrwFlYrVIPAQ8A7wELgG5Y7Z6vNca0uIOZtcR+FlZ5wACZwP+tUtNuMURkPPA5sAEI2Jt/jVXHjoTvvrb4JxMZ3/8QrIOoTqyB8QJjzO/s/8PzgTbAGmCKMaY0fJFWF/EJXimlVM0ivUSjlFKqFprglVIqSmmCV0qpKKUJXimlopQmeKWUilKa4FVMERF/lc6Fa5uzA6mI9KjaqVKpcHPV/xSlokqxfbq5UlFPR/BKUdmX/092b/5vRKSPvb2HiHxiN8NaIiLd7O3tReRduz/4OhE5w96VU0Tm2D3D/22f9ahUWGiCV7Em4YQSzXVVHss1xmQA/8A6Oxrg78BLxpghwKvA4/b2x4GlxpihwAhgk729L/CEMWYQcAy4OsSfR6la6ZmsKqaISIExJqmG7ZnA2caYXXZTrIPGmLYikoO1UEW5vT3LGJMmItlAl6qnpdttcBcbY/ra9+8F3MaYP4T+kyl1Mh3BK3WcqeV2Q1TtQ+JHj3OpMNIEr9Rx11W5/sq+/SVWl1KAG7EaZgEsAe6AyoUgUk5VkEoFS0cXKtYk2KvyVPjIGFMxVTJVRNZjjcIn29vuAl4UkZlANjDN3j4DeFZEbsMaqd+BtWCFUi2G1uCVIvIWP1cqGFqiUUqpKKUjeKWUilI6gldKqSilCV4ppaKUJnillIpSmuCVUipKaYJXSqko9f8Bfn7c0yQo0jcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}