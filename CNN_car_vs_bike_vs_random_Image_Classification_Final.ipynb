{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN car vs bike vs random Image Classification_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shuvamjoy34/NumberCrunchers/blob/master/CNN_car_vs_bike_vs_random_Image_Classification_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IwzPSB_5BdE"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "from keras.utils.data_utils import Sequence\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.keras import balanced_batch_generator"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws4O_ErfJ2Dh",
        "outputId": "42906500-a4af-46bb-d399-648a08c3235f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvMbsJ3t5Pec"
      },
      "source": [
        "data=[]\n",
        "labels=[]\n",
        "car=os.listdir(\"/content/drive/My Drive/Images/car/\")\n",
        "for a in car:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/car/\"+a)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128, 128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(0)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "\n",
        "bike=os.listdir(\"/content/drive/My Drive/Images/bike/\")\n",
        "for b in bike:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/bike/\"+b)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128,128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(1)\n",
        "    except AttributeError:\n",
        "        print(\"\")\n",
        "random=os.listdir(\"/content/drive/My Drive/Images/random/\")\n",
        "for c in random:\n",
        "    try:\n",
        "        image=cv2.imread(\"/content/drive/My Drive/Images/random/\"+c)\n",
        "        image_from_array = Image.fromarray(image, 'RGB')\n",
        "        size_image = image_from_array.resize((128, 128))\n",
        "        data.append(np.array(size_image))\n",
        "        labels.append(2)\n",
        "    except AttributeError:\n",
        "        print(\"\")"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5VbX_iG5tDU"
      },
      "source": [
        "images=np.array(data)\n",
        "labels=np.array(labels)"
      ],
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpIgw9cX7Brg"
      },
      "source": [
        "s=np.arange(images.shape[0])\n",
        "np.random.shuffle(s)\n",
        "images=images[s]\n",
        "labels=labels[s]\n",
        "num_classes=len(np.unique(labels))\n",
        "len_data=len(images)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KuERdWF7C2h",
        "outputId": "b73ea591-bbc6-4759-938c-f41d876e0570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "images =images.astype(np.float32)\n",
        "images = images/255\n",
        "\n",
        "train_x , x , train_y , y = train_test_split(images , labels , \n",
        "                                            test_size = 0.2 ,\n",
        "                                            random_state = 111)\n",
        "\n",
        "eval_x , test_x , eval_y , test_y = train_test_split(x , y , \n",
        "                                                    test_size = 0.5 , \n",
        "                                                    random_state = 111)\n",
        "\n",
        "plt.figure(1 , figsize = (15 ,5))\n",
        "n = 0 \n",
        "for z , j in zip([train_y , eval_y , test_y] , ['train labels','eval labels','test labels']):\n",
        "    n += 1\n",
        "    plt.subplot(1 , 3  , n)\n",
        "    sns.countplot(x = z )\n",
        "    plt.title(j)\n",
        "plt.show()"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqGsbD8a_DsY"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "train_y = lb.fit_transform(train_y)\n",
        "test_y = lb.transform(test_y)\n",
        "eval_y = lb.transform(eval_y)\n"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QuZ9pYQLquy"
      },
      "source": [
        "from tensorflow.python.keras import regularizers\n",
        "from keras.layers.normalization import BatchNormalization\n"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTaPHgBu_ULu",
        "outputId": "6e1fcd16-fb9a-47d6-d112-b828c9ddb059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        }
      },
      "source": [
        "#BasicConvNet\n",
        "classifier = Sequential()\n",
        "\n",
        "classifier.add(Conv2D(filters=32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(128,128,3)))\n",
        "#keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "classifier.add(Conv2D(filters=32,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "classifier.add(Conv2D(filters=64,kernel_size=(3,3),padding='valid',activation='relu',kernel_regularizer=regularizers.l2(0.05)))\n",
        "#keras.layers.BatchNormalization()\n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "classifier.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "classifier.add(Flatten())\n",
        "\n",
        "classifier.add(Dense(500,activation=\"relu\"))\n",
        "\n",
        "classifier.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "\n",
        "classifier.add(Dense(3,activation=\"softmax\"))#2 represent output layer neurons \n",
        "\n",
        "classifier.summary()"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_75 (Conv2D)           (None, 126, 126, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_51 (MaxPooling (None, 63, 63, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 61, 61, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_52 (MaxPooling (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_53 (MaxPooling (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 500)               6272500   \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 3)                 1503      \n",
            "=================================================================\n",
            "Total params: 6,302,643\n",
            "Trainable params: 6,302,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SCq_1GKM5Lb",
        "outputId": "60de8e24-d50d-4037-bca7-13f57fec055a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "source": [
        "! pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_c3aQTCBO0W",
        "outputId": "92352bbd-9eb5-4178-e334-eb8b0a7b9170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#checkpoint = ModelCheckpoint(\"convnet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "#early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "#from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)\n",
        "\n",
        "classifier.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "shuvam= classifier.fit(train_x,train_y,batch_size = 32,epochs=200,verbose=1,validation_data=(eval_x, eval_y))\n",
        "shuvam"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 5.7863 - accuracy: 0.3750 - val_loss: 4.5518 - val_accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.4410 - accuracy: 0.4000 - val_loss: 4.1555 - val_accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 4.0296 - accuracy: 0.6000 - val_loss: 3.6225 - val_accuracy: 0.9000\n",
            "Epoch 4/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 3.6635 - accuracy: 0.7375 - val_loss: 3.2708 - val_accuracy: 0.9000\n",
            "Epoch 5/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 3.2460 - accuracy: 0.8750 - val_loss: 2.8987 - val_accuracy: 0.9000\n",
            "Epoch 6/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 2.9253 - accuracy: 0.8875 - val_loss: 2.6248 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.6454 - accuracy: 0.9625 - val_loss: 2.3841 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.4229 - accuracy: 0.9625 - val_loss: 2.2638 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 2.2831 - accuracy: 0.9375 - val_loss: 2.1067 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 2.1129 - accuracy: 0.9500 - val_loss: 1.9902 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.9900 - accuracy: 0.9750 - val_loss: 1.8306 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.8454 - accuracy: 0.9875 - val_loss: 1.7252 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.7192 - accuracy: 1.0000 - val_loss: 1.6260 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.6200 - accuracy: 1.0000 - val_loss: 1.5355 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.5349 - accuracy: 1.0000 - val_loss: 1.4502 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.4333 - accuracy: 1.0000 - val_loss: 1.3950 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.3703 - accuracy: 1.0000 - val_loss: 1.3092 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.3008 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2307 - accuracy: 1.0000 - val_loss: 1.1768 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1701 - accuracy: 1.0000 - val_loss: 1.1237 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.1115 - accuracy: 1.0000 - val_loss: 1.0691 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0514 - accuracy: 1.0000 - val_loss: 1.0164 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.0179 - accuracy: 1.0000 - val_loss: 0.9669 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.9842 - accuracy: 0.9875 - val_loss: 0.9389 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.9243 - accuracy: 1.0000 - val_loss: 0.8953 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.8874 - accuracy: 1.0000 - val_loss: 0.8566 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.8457 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.8176 - accuracy: 1.0000 - val_loss: 0.7884 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7869 - accuracy: 1.0000 - val_loss: 0.7570 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.7490 - accuracy: 1.0000 - val_loss: 0.7318 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.7227 - accuracy: 1.0000 - val_loss: 0.6996 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6932 - accuracy: 1.0000 - val_loss: 0.6761 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6714 - accuracy: 1.0000 - val_loss: 0.6522 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6450 - accuracy: 1.0000 - val_loss: 0.6311 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.6233 - accuracy: 1.0000 - val_loss: 0.6042 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5976 - accuracy: 1.0000 - val_loss: 0.5834 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5774 - accuracy: 1.0000 - val_loss: 0.5633 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5565 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5377 - accuracy: 1.0000 - val_loss: 0.5268 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5186 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5019 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.4888 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4705 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4552 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4427 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4257 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4177 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.4070 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3956 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3842 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.3817 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3639 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3510 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3409 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3279 - accuracy: 1.0000 - val_loss: 0.3237 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3200 - accuracy: 1.0000 - val_loss: 0.3161 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.3107 - accuracy: 1.0000 - val_loss: 0.3080 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3007 - accuracy: 1.0000 - val_loss: 0.3089 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2941 - accuracy: 1.0000 - val_loss: 0.2897 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2844 - accuracy: 1.0000 - val_loss: 0.2816 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2776 - accuracy: 1.0000 - val_loss: 0.2722 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2687 - accuracy: 1.0000 - val_loss: 0.2656 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2624 - accuracy: 1.0000 - val_loss: 0.2576 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2541 - accuracy: 1.0000 - val_loss: 0.2512 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.2443 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2416 - accuracy: 1.0000 - val_loss: 0.2385 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2349 - accuracy: 1.0000 - val_loss: 0.2312 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2287 - accuracy: 1.0000 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2221 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2163 - accuracy: 1.0000 - val_loss: 0.2152 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.2105 - accuracy: 1.0000 - val_loss: 0.2086 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2064 - accuracy: 1.0000 - val_loss: 0.2030 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 0.1979 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1969 - accuracy: 1.0000 - val_loss: 0.1937 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1898 - accuracy: 1.0000 - val_loss: 0.1884 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1851 - accuracy: 1.0000 - val_loss: 0.1856 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1808 - accuracy: 1.0000 - val_loss: 0.1795 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1763 - accuracy: 1.0000 - val_loss: 0.1766 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1722 - accuracy: 1.0000 - val_loss: 0.1719 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1682 - accuracy: 1.0000 - val_loss: 0.1669 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1644 - accuracy: 1.0000 - val_loss: 0.1629 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1596 - accuracy: 1.0000 - val_loss: 0.1598 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1562 - accuracy: 1.0000 - val_loss: 0.1582 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1535 - accuracy: 1.0000 - val_loss: 0.1512 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1510 - accuracy: 1.0000 - val_loss: 0.1477 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1452 - accuracy: 1.0000 - val_loss: 0.1510 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1415 - accuracy: 1.0000 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1410 - accuracy: 1.0000 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1380 - accuracy: 1.0000 - val_loss: 0.1356 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1331 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1323 - accuracy: 1.0000 - val_loss: 0.1318 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1244 - accuracy: 1.0000 - val_loss: 0.1262 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1223 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1193 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1161 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1133 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1096 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1113 - accuracy: 1.0000 - val_loss: 0.1306 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1196 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.8000\n",
            "Epoch 101/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4479 - accuracy: 0.8375 - val_loss: 0.6346 - val_accuracy: 0.8000\n",
            "Epoch 102/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4575 - accuracy: 0.8750 - val_loss: 0.3930 - val_accuracy: 0.9000\n",
            "Epoch 103/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2735 - accuracy: 0.9500 - val_loss: 0.2021 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1709 - accuracy: 0.9875 - val_loss: 0.2225 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1593 - accuracy: 1.0000 - val_loss: 0.2299 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1930 - accuracy: 0.9625 - val_loss: 0.2618 - val_accuracy: 0.9000\n",
            "Epoch 107/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1642 - accuracy: 0.9875 - val_loss: 0.1757 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1666 - accuracy: 1.0000 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1559 - accuracy: 1.0000 - val_loss: 0.1610 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1526 - accuracy: 1.0000 - val_loss: 0.1504 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.1599 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1508 - accuracy: 1.0000 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1390 - accuracy: 1.0000 - val_loss: 0.1428 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1378 - accuracy: 1.0000 - val_loss: 0.1433 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1357 - accuracy: 1.0000 - val_loss: 0.1374 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1305 - accuracy: 1.0000 - val_loss: 0.1299 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1267 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1240 - accuracy: 1.0000 - val_loss: 0.1345 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1217 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1156 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1125 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1109 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1072 - accuracy: 1.0000 - val_loss: 0.1083 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1053 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1122 - accuracy: 0.9875 - val_loss: 0.1050 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1021 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1014 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0986 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 1.0000 - val_loss: 0.0985 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0934 - accuracy: 1.0000 - val_loss: 0.0996 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0932 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0882 - accuracy: 1.0000 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0872 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0854 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0840 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0816 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0810 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0766 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0758 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0731 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0793 - accuracy: 1.0000 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0722 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0719 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0699 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0674 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0661 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0642 - accuracy: 1.0000 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0636 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0625 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0620 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0616 - accuracy: 1.0000 - val_loss: 0.0633 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.0629 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0601 - accuracy: 1.0000 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0578 - accuracy: 1.0000 - val_loss: 0.0603 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0591 - accuracy: 1.0000 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0567 - accuracy: 1.0000 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0552 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0524 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.0518 - accuracy: 1.0000 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0513 - accuracy: 1.0000 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0504 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0508 - accuracy: 1.0000 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0508 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0489 - accuracy: 1.0000 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0475 - accuracy: 1.0000 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 0.0513 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.0495 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0459 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0448 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0450 - accuracy: 1.0000 - val_loss: 0.0464 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0447 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 0.0453 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0460 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0416 - accuracy: 1.0000 - val_loss: 0.0461 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0409 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0403 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e23036828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk4iuwnVC-TV",
        "outputId": "64e481b3-f5b9-4588-a300-4aaceab6891e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(shuvam.history[\"accuracy\"])\n",
        "plt.plot(shuvam.history['val_accuracy'])\n",
        "plt.plot(shuvam.history['loss'])\n",
        "plt.plot(shuvam.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH5y963j_b1k"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras \n",
        "\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from cv2 import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.layers import Dense, Dropout, Flatten, Input, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from numpy import array \n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "#config = tf.ConfigProto()\n",
        "#config.gpu_options.allow_growth = True\n",
        "#sess = tf.Session(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeoWYDPiBVTM"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.,\n",
        "                                  horizontal_flip = True,\n",
        "                                  zoom_range = 0.3,\n",
        "                                  rotation_range = 30)\n",
        "val_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow(train_x,train_y, batch_size=32)\n",
        "val_gen = val_datagen.flow(eval_x,eval_y, batch_size=32)\n",
        "test_gen = val_datagen.flow(test_x,test_y, batch_size =32, shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmrxG-bLv_tB",
        "outputId": "991bf4eb-59c2-4479-cbd9-17be6a42fe2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "ep = 100\n",
        "classifier.fit_generator(generator = train_gen, validation_data= val_gen,\n",
        "                           steps_per_epoch=STEP_SIZE_TRAIN, epochs=ep, \n",
        "                           validation_steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 146ms/step - loss: 4.8851 - accuracy: 0.4583\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 2.0396 - accuracy: 0.4167\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.8759 - accuracy: 0.4583\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.2548 - accuracy: 0.5208\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.0878 - accuracy: 0.5417\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.1213 - accuracy: 0.4688\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.1590 - accuracy: 0.4792\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.1515 - accuracy: 0.6250\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.1555 - accuracy: 0.4844\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.1645 - accuracy: 0.4583\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 1.1114 - accuracy: 0.5833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.0617 - accuracy: 0.6042\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.1824 - accuracy: 0.4844\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.1043 - accuracy: 0.5625\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.1516 - accuracy: 0.4844\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.0695 - accuracy: 0.6094\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.0938 - accuracy: 0.5469\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.0932 - accuracy: 0.5208\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 1.0737 - accuracy: 0.5833\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 1.1772 - accuracy: 0.4583\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.1761 - accuracy: 0.4375\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.1665 - accuracy: 0.4531\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1550 - accuracy: 0.4844\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 246ms/step - loss: 1.1242 - accuracy: 0.5417\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 247ms/step - loss: 1.1438 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 246ms/step - loss: 1.1393 - accuracy: 0.5000\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.1070 - accuracy: 0.5625\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.0892 - accuracy: 0.5417\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.1358 - accuracy: 0.4844\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.1276 - accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.1562 - accuracy: 0.4792\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.0874 - accuracy: 0.5417\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.1701 - accuracy: 0.4167\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.1863 - accuracy: 0.3750\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.1146 - accuracy: 0.5417\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.1269 - accuracy: 0.5156\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.1318 - accuracy: 0.5156\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.1384 - accuracy: 0.4792\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 246ms/step - loss: 1.1477 - accuracy: 0.4531\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.0877 - accuracy: 0.5833\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0615 - accuracy: 0.6042\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.1256 - accuracy: 0.5000\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 1.1102 - accuracy: 0.5000\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 248ms/step - loss: 1.0505 - accuracy: 0.5833\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1303 - accuracy: 0.5000\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 1.1632 - accuracy: 0.4375\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 1.1022 - accuracy: 0.5000\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.0686 - accuracy: 0.5417\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.1363 - accuracy: 0.4375\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.0856 - accuracy: 0.5417\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.1028 - accuracy: 0.5000\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.0876 - accuracy: 0.5417\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.0431 - accuracy: 0.6042\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.0804 - accuracy: 0.5208\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0793 - accuracy: 0.5312\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.1449 - accuracy: 0.4583\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0158 - accuracy: 0.6042\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.1122 - accuracy: 0.4844\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1138 - accuracy: 0.4844\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.0040 - accuracy: 0.6042\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.0500 - accuracy: 0.5625\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.1019 - accuracy: 0.4792\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.0860 - accuracy: 0.5156\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 1.1443 - accuracy: 0.4167\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.1198 - accuracy: 0.4583\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.0770 - accuracy: 0.5417\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.0363 - accuracy: 0.5625\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.0802 - accuracy: 0.5000\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.0918 - accuracy: 0.4844\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0733 - accuracy: 0.5156\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 246ms/step - loss: 1.0967 - accuracy: 0.4844\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 1.0883 - accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.0810 - accuracy: 0.5000\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 1.0483 - accuracy: 0.5469\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.0824 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0816 - accuracy: 0.5156\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 1.0939 - accuracy: 0.4792\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.0575 - accuracy: 0.5417\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 1.0690 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.0937 - accuracy: 0.4792\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.0439 - accuracy: 0.5417\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.1465 - accuracy: 0.4167\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.0620 - accuracy: 0.5417\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 1.0720 - accuracy: 0.5000\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.0559 - accuracy: 0.5417\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.1051 - accuracy: 0.4792\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.0511 - accuracy: 0.5312\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.0746 - accuracy: 0.5156\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.0567 - accuracy: 0.5312\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.0724 - accuracy: 0.5000\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.0271 - accuracy: 0.5625\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.0512 - accuracy: 0.5417\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.0460 - accuracy: 0.5417\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.1100 - accuracy: 0.4792\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.0561 - accuracy: 0.5156\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 242ms/step - loss: 1.0806 - accuracy: 0.4844\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.0285 - accuracy: 0.5625\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.0775 - accuracy: 0.4792\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.0785 - accuracy: 0.4844\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.1181 - accuracy: 0.4375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff729cf75c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4OOZImRwOZW",
        "outputId": "37361dbf-6fee-4473-f622-07140135eeb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "score = classifier.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.35637736320495605\n",
            "Test accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfJUUhfA2RM2",
        "outputId": "de88d8eb-3530-433a-a293-b882040478f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = classifier.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4e215fd2f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       1.00      0.50      0.67         2\n",
            "  class 1(bike)       1.00      1.00      1.00         3\n",
            "class 2(random)       0.83      1.00      0.91         5\n",
            "\n",
            "       accuracy                           0.90        10\n",
            "      macro avg       0.94      0.83      0.86        10\n",
            "   weighted avg       0.92      0.90      0.89        10\n",
            "\n",
            "[[1 0 1]\n",
            " [0 3 0]\n",
            " [0 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YIr9Px0pjcc"
      },
      "source": [
        "\n",
        "#AlexNet\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(128,128,3)),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=384, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "    #keras.layers.BatchNormalization(),\n",
        "    keras.layers.Conv2D(filters=256, kernel_size=(1,1), strides=(1,1), activation='relu', padding=\"same\"),\n",
        "   # keras.layers.BatchNormalization(),\n",
        "    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(500, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(500, activation='relu'),\n",
        "    keras.layers.Dropout(0.2),\n",
        "    keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0YQ7j7Lpvv_",
        "outputId": "e0f1c6e5-d431-42ce-f525-46547449c8bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        }
      },
      "source": [
        "\n",
        "model.summary()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_31 (Conv2D)           (None, 62, 62, 96)        34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 62, 62, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling (None, 30, 30, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 30, 30, 256)       614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 30, 30, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 14, 14, 384)       885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 14, 14, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 14, 14, 384)       147840    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 14, 14, 384)       1536      \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 14, 14, 256)       98560     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 14, 14, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 500)               4608500   \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 1503      \n",
            "=================================================================\n",
            "Total params: 6,647,127\n",
            "Trainable params: 6,644,375\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg64Pmo1qFhM",
        "outputId": "a8794559-f9c7-48ca-9e26-f823a9de6bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"alexnet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "#from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "lizon=model.fit(train_x,train_y,batch_size = 32,epochs=200,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])\n",
        "lizon"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/200\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.2865 - accuracy: 0.4750\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to alexnet_1.h5\n",
            "3/3 [==============================] - 0s 153ms/step - loss: 1.2865 - accuracy: 0.4750 - val_loss: 1.1009 - val_accuracy: 0.5000\n",
            "Epoch 2/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0870 - accuracy: 0.4375\n",
            "Epoch 00002: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0882 - accuracy: 0.4000 - val_loss: 1.0872 - val_accuracy: 0.5000\n",
            "Epoch 3/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0441 - accuracy: 0.5312\n",
            "Epoch 00003: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0781 - accuracy: 0.5000 - val_loss: 1.0794 - val_accuracy: 0.5000\n",
            "Epoch 4/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0894 - accuracy: 0.3750\n",
            "Epoch 00004: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0787 - accuracy: 0.4625 - val_loss: 1.0995 - val_accuracy: 0.5000\n",
            "Epoch 5/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0664 - accuracy: 0.4688\n",
            "Epoch 00005: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0655 - accuracy: 0.5000 - val_loss: 1.1090 - val_accuracy: 0.5000\n",
            "Epoch 6/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.1017 - accuracy: 0.4062\n",
            "Epoch 00006: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0477 - accuracy: 0.5000 - val_loss: 1.0901 - val_accuracy: 0.5000\n",
            "Epoch 7/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0002 - accuracy: 0.5312\n",
            "Epoch 00007: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0662 - accuracy: 0.5000 - val_loss: 1.0127 - val_accuracy: 0.5000\n",
            "Epoch 8/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0215 - accuracy: 0.5000\n",
            "Epoch 00008: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0135 - accuracy: 0.5000 - val_loss: 0.9619 - val_accuracy: 0.5000\n",
            "Epoch 9/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0215 - accuracy: 0.4062\n",
            "Epoch 00009: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9747 - accuracy: 0.5000 - val_loss: 1.0925 - val_accuracy: 0.5000\n",
            "Epoch 10/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0551 - accuracy: 0.5000\n",
            "Epoch 00010: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9650 - accuracy: 0.5000 - val_loss: 0.9054 - val_accuracy: 0.5000\n",
            "Epoch 11/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9840 - accuracy: 0.4688\n",
            "Epoch 00011: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9461 - accuracy: 0.5000 - val_loss: 0.8346 - val_accuracy: 0.5000\n",
            "Epoch 12/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8444 - accuracy: 0.4375\n",
            "Epoch 00012: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8733 - accuracy: 0.5000 - val_loss: 0.7822 - val_accuracy: 0.5000\n",
            "Epoch 13/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.6697 - accuracy: 0.5938\n",
            "Epoch 00013: val_accuracy improved from 0.50000 to 0.80000, saving model to alexnet_1.h5\n",
            "3/3 [==============================] - 0s 103ms/step - loss: 0.8254 - accuracy: 0.5375 - val_loss: 0.7575 - val_accuracy: 0.8000\n",
            "Epoch 14/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8504 - accuracy: 0.5938\n",
            "Epoch 00014: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8615 - accuracy: 0.5750 - val_loss: 0.6731 - val_accuracy: 0.8000\n",
            "Epoch 15/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8019 - accuracy: 0.6250\n",
            "Epoch 00015: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0052 - accuracy: 0.4375 - val_loss: 0.8532 - val_accuracy: 0.6000\n",
            "Epoch 16/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0238 - accuracy: 0.3750\n",
            "Epoch 00016: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9677 - accuracy: 0.4875 - val_loss: 1.1848 - val_accuracy: 0.5000\n",
            "Epoch 17/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0526 - accuracy: 0.5000\n",
            "Epoch 00017: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9565 - accuracy: 0.5000 - val_loss: 0.8744 - val_accuracy: 0.5000\n",
            "Epoch 18/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8749 - accuracy: 0.5000\n",
            "Epoch 00018: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8858 - accuracy: 0.5000 - val_loss: 0.8865 - val_accuracy: 0.5000\n",
            "Epoch 19/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8460 - accuracy: 0.5625\n",
            "Epoch 00019: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8431 - accuracy: 0.5000 - val_loss: 0.8543 - val_accuracy: 0.5000\n",
            "Epoch 20/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7155 - accuracy: 0.6250\n",
            "Epoch 00020: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.8066 - accuracy: 0.5000 - val_loss: 0.8380 - val_accuracy: 0.5000\n",
            "Epoch 21/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8283 - accuracy: 0.4062\n",
            "Epoch 00021: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.7781 - accuracy: 0.5000 - val_loss: 1.0904 - val_accuracy: 0.5000\n",
            "Epoch 22/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9710 - accuracy: 0.4688\n",
            "Epoch 00022: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8596 - accuracy: 0.5750 - val_loss: 0.8908 - val_accuracy: 0.6000\n",
            "Epoch 23/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8436 - accuracy: 0.5938\n",
            "Epoch 00023: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9290 - accuracy: 0.6250 - val_loss: 0.8366 - val_accuracy: 0.7000\n",
            "Epoch 24/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7558 - accuracy: 0.5625\n",
            "Epoch 00024: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8723 - accuracy: 0.5125 - val_loss: 0.9686 - val_accuracy: 0.4000\n",
            "Epoch 25/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0808 - accuracy: 0.3125\n",
            "Epoch 00025: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.0511 - accuracy: 0.3250 - val_loss: 0.9873 - val_accuracy: 0.4000\n",
            "Epoch 26/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0246 - accuracy: 0.4062\n",
            "Epoch 00026: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9322 - accuracy: 0.4875 - val_loss: 0.9817 - val_accuracy: 0.5000\n",
            "Epoch 27/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8718 - accuracy: 0.3750\n",
            "Epoch 00027: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 1.1640 - accuracy: 0.4875 - val_loss: 0.9594 - val_accuracy: 0.4000\n",
            "Epoch 28/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9180 - accuracy: 0.5312\n",
            "Epoch 00028: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.9844 - accuracy: 0.4750 - val_loss: 0.9628 - val_accuracy: 0.5000\n",
            "Epoch 29/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0329 - accuracy: 0.5000\n",
            "Epoch 00029: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 1.0181 - accuracy: 0.5000 - val_loss: 0.9869 - val_accuracy: 0.5000\n",
            "Epoch 30/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.0130 - accuracy: 0.5312\n",
            "Epoch 00030: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 1.0188 - accuracy: 0.5000 - val_loss: 0.9230 - val_accuracy: 0.5000\n",
            "Epoch 31/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9086 - accuracy: 0.5625\n",
            "Epoch 00031: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.9378 - accuracy: 0.5250 - val_loss: 0.8110 - val_accuracy: 0.8000\n",
            "Epoch 32/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9046 - accuracy: 0.4688\n",
            "Epoch 00032: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.8311 - accuracy: 0.5500 - val_loss: 0.8537 - val_accuracy: 0.5000\n",
            "Epoch 33/200\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7745 - accuracy: 0.5000\n",
            "Epoch 00033: val_accuracy did not improve from 0.80000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.8212 - accuracy: 0.5500 - val_loss: 0.5555 - val_accuracy: 0.8000\n",
            "Epoch 00033: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e251922b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWTB5BinJv2k",
        "outputId": "8eec99d1-9afd-491b-c678-3168d9846c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lizon.history[\"accuracy\"])\n",
        "plt.plot(lizon.history['val_accuracy'])\n",
        "plt.plot(lizon.history['loss'])\n",
        "plt.plot(lizon.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF1B1r82sUEx"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.,\n",
        "                                  horizontal_flip = True,\n",
        "                                  zoom_range = 0.3,\n",
        "                                  rotation_range = 30)\n",
        "val_datagen= ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_gen = train_datagen.flow(train_x,train_y, batch_size=32)\n",
        "val_gen = val_datagen.flow(eval_x,eval_y, batch_size=32)\n",
        "test_gen = val_datagen.flow(test_x,test_y, batch_size =32, shuffle = False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPHolMmlsWT0",
        "outputId": "0347631f-701b-4dd5-9617-5364c38dfd66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "STEP_SIZE_TRAIN=train_gen.n//train_gen.batch_size\n",
        "STEP_SIZE_VALID=val_gen.n//val_gen.batch_size\n",
        "STEP_SIZE_TEST=test_gen.n//test_gen.batch_size\n",
        "ep = 100\n",
        "classifier.fit_generator(generator = train_gen, validation_data= val_gen,\n",
        "                           steps_per_epoch=STEP_SIZE_TRAIN, epochs=ep, \n",
        "                           validation_steps=STEP_SIZE_VALID)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-43-372460def1fa>:7: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 260ms/step - loss: 13.1706 - accuracy: 0.4531\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 4.7036 - accuracy: 0.2812\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 2.4718 - accuracy: 0.3125\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 2.6478 - accuracy: 0.3281\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.4242 - accuracy: 0.5208\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 2.0586 - accuracy: 0.3750\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.7608 - accuracy: 0.4688\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.4726 - accuracy: 0.4167\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.5628 - accuracy: 0.2708\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.4352 - accuracy: 0.4583\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.5146 - accuracy: 0.3750\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.6093 - accuracy: 0.2083\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 1.4686 - accuracy: 0.3750\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.5262 - accuracy: 0.2969\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3943 - accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3305 - accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.4633 - accuracy: 0.4219\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2938 - accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 1.3391 - accuracy: 0.5000\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.4269 - accuracy: 0.3958\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.2853 - accuracy: 0.5625\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.4078 - accuracy: 0.4792\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.3090 - accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.3374 - accuracy: 0.4219\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.3978 - accuracy: 0.4167\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.4137 - accuracy: 0.3125\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.3347 - accuracy: 0.4219\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.3217 - accuracy: 0.4375\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2602 - accuracy: 0.5625\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 1.3404 - accuracy: 0.4583\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 1.3253 - accuracy: 0.5000\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2566 - accuracy: 0.5833\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 1.2814 - accuracy: 0.5417\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.3491 - accuracy: 0.4583\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.3130 - accuracy: 0.4792\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.2932 - accuracy: 0.4583\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 245ms/step - loss: 1.2566 - accuracy: 0.4844\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.3359 - accuracy: 0.4792\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.3562 - accuracy: 0.4375\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.3591 - accuracy: 0.4167\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 1.2879 - accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.3309 - accuracy: 0.4583\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.3367 - accuracy: 0.4167\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 1.2921 - accuracy: 0.4531\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 242ms/step - loss: 1.2737 - accuracy: 0.4583\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 240ms/step - loss: 1.3158 - accuracy: 0.4844\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 1.2376 - accuracy: 0.5208\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2570 - accuracy: 0.4688\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2525 - accuracy: 0.5156\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2553 - accuracy: 0.5000\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1675 - accuracy: 0.5833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 243ms/step - loss: 1.2550 - accuracy: 0.5000\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2587 - accuracy: 0.4688\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 244ms/step - loss: 1.2586 - accuracy: 0.4844\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.3249 - accuracy: 0.4375\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2855 - accuracy: 0.5000\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.2774 - accuracy: 0.4583\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 1.2515 - accuracy: 0.4583\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2216 - accuracy: 0.5000\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2721 - accuracy: 0.5208\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 1.2436 - accuracy: 0.4792\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2357 - accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2404 - accuracy: 0.4792\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 1.2609 - accuracy: 0.4375\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2583 - accuracy: 0.5000\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2164 - accuracy: 0.5156\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2646 - accuracy: 0.4531\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2540 - accuracy: 0.4844\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2643 - accuracy: 0.4792\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.2572 - accuracy: 0.5000\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 242ms/step - loss: 1.2325 - accuracy: 0.4531\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.2722 - accuracy: 0.4167\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 236ms/step - loss: 1.2524 - accuracy: 0.4688\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 234ms/step - loss: 1.2337 - accuracy: 0.4583\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 1.2185 - accuracy: 0.5000\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 239ms/step - loss: 1.3037 - accuracy: 0.4583\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 1.2249 - accuracy: 0.5208\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.1717 - accuracy: 0.5625\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.2451 - accuracy: 0.5000\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2073 - accuracy: 0.5208\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.2266 - accuracy: 0.4792\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 235ms/step - loss: 1.2072 - accuracy: 0.5312\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 241ms/step - loss: 1.2370 - accuracy: 0.4792\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2010 - accuracy: 0.5417\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2507 - accuracy: 0.4688\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 1.2115 - accuracy: 0.5625\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 237ms/step - loss: 1.2301 - accuracy: 0.4844\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 230ms/step - loss: 1.2145 - accuracy: 0.5156\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 238ms/step - loss: 1.1932 - accuracy: 0.5208\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.2508 - accuracy: 0.4583\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 232ms/step - loss: 1.1752 - accuracy: 0.5417\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 229ms/step - loss: 1.1792 - accuracy: 0.5417\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 233ms/step - loss: 1.2217 - accuracy: 0.4844\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 1.2071 - accuracy: 0.5000\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 226ms/step - loss: 1.2282 - accuracy: 0.5000\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.1774 - accuracy: 0.5417\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 231ms/step - loss: 1.2537 - accuracy: 0.4531\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 1.2156 - accuracy: 0.5208\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 227ms/step - loss: 1.2483 - accuracy: 0.4583\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 228ms/step - loss: 1.2007 - accuracy: 0.5469\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ebc0c95f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHAob_P6qpO6",
        "outputId": "1458ac47-5900-4a2c-d419-b29b45247b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "alexscore = model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', alexscore[0])\n",
        "print('Test accuracy:', alexscore[1])"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.43827977776527405\n",
            "Test accuracy: 0.800000011920929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZAcXDv4qtnc",
        "outputId": "bdada288-f3e1-4e2c-ac53-7689ca7f9263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = model.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), Y_pred))"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4e20296620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.00      0.00      0.00         2\n",
            "  class 1(bike)       1.00      1.00      1.00         3\n",
            "class 2(random)       0.71      1.00      0.83         5\n",
            "\n",
            "       accuracy                           0.80        10\n",
            "      macro avg       0.57      0.67      0.61        10\n",
            "   weighted avg       0.66      0.80      0.72        10\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-186-4e7eae5765a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH-ZuqHW2L3x"
      },
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA5xkUha1BUo"
      },
      "source": [
        "#vgg16\n",
        "vggmodel = Sequential()\n",
        "vggmodel.add(Conv2D(input_shape=(256,256,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "vggmodel.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-Oa35rl2Q5M"
      },
      "source": [
        "vggmodel.add(Flatten())\n",
        "vggmodel.add(Dense(units=500,activation=\"relu\"))\n",
        "keras.layers.Dropout(0.2)\n",
        "vggmodel.add(Dense(units=500,activation=\"relu\"))\n",
        "keras.layers.Dropout(0.2)\n",
        "vggmodel.add(Dense(units=3, activation=\"softmax\"))"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj3OkIly2xbF",
        "outputId": "e95a1700-76e1-4c14-cc75-560d6fd08bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        }
      },
      "source": [
        "vggmodel.summary()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_88 (Conv2D)           (None, 256, 256, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_89 (Conv2D)           (None, 256, 256, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_60 (MaxPooling (None, 128, 128, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_90 (Conv2D)           (None, 128, 128, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_91 (Conv2D)           (None, 128, 128, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_61 (MaxPooling (None, 64, 64, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_92 (Conv2D)           (None, 64, 64, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_93 (Conv2D)           (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_94 (Conv2D)           (None, 64, 64, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_62 (MaxPooling (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_95 (Conv2D)           (None, 32, 32, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_96 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_97 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_63 (MaxPooling (None, 16, 16, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_98 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_99 (Conv2D)           (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_100 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_64 (MaxPooling (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_19 (Flatten)         (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 500)               16384500  \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 3)                 1503      \n",
            "=================================================================\n",
            "Total params: 31,351,191\n",
            "Trainable params: 31,351,191\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-97kUBD_ZfaH"
      },
      "source": [
        "#from keras.optimizers import Adam\n",
        "#opt = Adam(lr=0.001)\n",
        "vggmodel.compile(optimizer=\"adam\", loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGczUBGS24ft",
        "outputId": "e492f124-8d5c-44cc-cd66-102076548e6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "#checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "#early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "vgg=vggmodel.fit(train_x,train_y,batch_size = 32,epochs=200,verbose=1,validation_data=(eval_x, eval_y))\n",
        "vgg"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 256, 256, 3) for input Tensor(\"conv2d_88_input:0\", shape=(None, 256, 256, 3), dtype=float32), but it was called on an input with incompatible shape (None, 128, 128, 3).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-193-bf3dd55d5b72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mvgg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvggmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mvgg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2826\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2828\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2829\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3141\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3142\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3143\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:372 call\n        return super(Sequential, self).call(inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:386 call\n        inputs, training=training, mask=mask)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py:508 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:976 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_45 is incompatible with the layer: expected axis -1 of input shape to have value 32768 but received input with shape [None, 8192]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3VfSOlu5Fd_",
        "outputId": "c7e9742a-2213-45f0-8703-96836a75e412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "vggscore = vggmodel.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', vggscore[0])\n",
        "print('Test accuracy:', vggscore[1])"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 2.089756727218628\n",
            "Test accuracy: 0.8999999761581421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xb0R3Ul5OzS",
        "outputId": "da427bc1-89f1-47de-9516-0944cdb43da6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "Y_pred = vggmodel.predict(test_x)\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       0.67      1.00      0.80         2\n",
            "  class 1(bike)       1.00      1.00      1.00         2\n",
            "class 2(random)       1.00      0.83      0.91         6\n",
            "\n",
            "       accuracy                           0.90        10\n",
            "      macro avg       0.89      0.94      0.90        10\n",
            "   weighted avg       0.93      0.90      0.91        10\n",
            "\n",
            "[[2 0 0]\n",
            " [0 2 0]\n",
            " [1 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEu6Rpr-BrvZ",
        "outputId": "22222774-df71-4b81-ec8f-9dac557e417e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(vgg.history[\"accuracy\"])\n",
        "plt.plot(vgg.history['val_accuracy'])\n",
        "plt.plot(vgg.history['loss'])\n",
        "plt.plot(vgg.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU9b3/8dcnC1kIWySALAooO8lACKCVVb1eFwQBFahbSgXFisVarz5sf+K1pdWWVq9Lte4bDahVhIp6BUSwoLIYdrmyBNm3sCRkneTz++OcjEMIIcRMJuF8no/HPDJn/8xhmPec7znzPaKqGGOM8a6IcBdgjDEmvCwIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjKeIyGsi8vsqzpslIpeHuiZjws2CwBhjPM6CwJh6SESiwl2DOXtYEJg6x22SuV9E1ojIcRF5WURaishHIpIjIvNFpFnQ/MNFZL2IHBGRRSLSLWhabxFZ5S43C4gtt61hIpLpLrtURFKqWOM1IvKNiBwTkR0i8ki56QPc9R1xp6e74+NE5C8isl1EjorIF+64ISKys4L9cLn7/BEReVdE3hKRY0C6iPQTkWXuNvaIyDMi0iBo+R4i8qmIZIvIPhF5SERaiUieiJwTNF+qiBwQkeiqvHZz9rEgMHXVaOA/gM7AtcBHwENAEs779h4AEekMZABT3GnzgLki0sD9UJwNvAkkAu+468VdtjfwCnAHcA7wd2COiMRUob7jwK1AU+AaYJKIXOeu93y33qfdmnoBme5y04E+wE/cmv4LKK3iPhkBvOtucwZQAtwLNAcuBi4D7nJraATMBz4GWgMXAgtUdS+wCLgxaL23ADNVtbiKdZizjAWBqaueVtV9qroLWAJ8parfqGoB8D7Q251vDPChqn7qfpBNB+JwPmgvAqKBJ1W1WFXfBZYHbWMi8HdV/UpVS1T1daDQXa5SqrpIVdeqaqmqrsEJo8Hu5J8C81U1w93uIVXNFJEIYDzwS1Xd5W5zqaoWVnGfLFPV2e4281V1pap+qap+Vc3CCbKyGoYBe1X1L6paoKo5qvqVO+114GYAEYkExuGEpfEoCwJTV+0Lep5fwXCC+7w1sL1sgqqWAjuANu60XXpiz4rbg56fD9znNq0cEZEjQDt3uUqJSH8R+cxtUjkK3InzzRx3HVsqWKw5TtNURdOqYke5GjqLyL9EZK/bXPSHKtQA8AHQXUQ64Bx1HVXVr6tZkzkLWBCY+m43zgc6ACIiOB+Cu4A9QBt3XJnzgp7vAKapatOgR7yqZlRhu/8A5gDtVLUJ8DxQtp0dwAUVLHMQKDjFtONAfNDriMRpVgpWvqvg54BvgU6q2hin6Sy4ho4VFe4eVb2Nc1RwC3Y04HkWBKa+exu4RkQuc0923ofTvLMUWAb4gXtEJFpERgH9gpZ9EbjT/XYvItLQPQncqArbbQRkq2qBiPTDaQ4qMwO4XERuFJEoETlHRHq5RyuvAH8VkdYiEikiF7vnJP4PiHW3Hw38FjjduYpGwDEgV0S6ApOCpv0LOFdEpohIjIg0EpH+QdPfANKB4VgQeJ4FganXVHUTzjfbp3G+cV8LXKuqRapaBIzC+cDLxjmf8F7QsiuACcAzwGFgsztvVdwFPCoiOcDDOIFUtt7vgatxQikb50Sxz538a2AtzrmKbOBxIEJVj7rrfAnnaOY4cMJVRBX4NU4A5eCE2qygGnJwmn2uBfYC3wFDg6b/G+ck9SpVDW4uMx4kdmMaY7xJRBYC/1DVl8JdiwkvCwJjPEhE+gKf4pzjyAl3PSa8rGnIGI8RkddxfmMwxULAgB0RGGOM59kRgTHGeFy967iqefPm2r59+3CXYYwx9crKlSsPqmr536YA9TAI2rdvz4oVK8JdhjHG1CsicsrLhK1pyBhjPM6CwBhjPM6CwBhjPM6CwBhjPM6CwBhjPM6CwBhjPM6CwBhjPM4zQeDPzmbfHx+j5MiRcJdijDF1imeC4PiyZWS/+SZbrryKw7PeRktKwl2SMcbUCZ4JgibXXEOH9/5JgwsvYO/UqWTdOIb8zMxwl2WMMWHnmSAAiO3alfPffJPWf/4z/gMHyBo7jt0P/Qb/wYPhLs0YY8LGU0EAICI0uXYYHefN45zbf87RuXPZcuVVZL/xBur3h7s8Y4ypdfXufgRpaWlak53OFW7dyr5pf+D4v/9NTKdOtPztb2nYv9/pFzQG0OJiinbsoHDLFoq3b6fk+HG0qAgtLEILC9GiQkqDhwsLKS0+cRgRYnv0ID4tjfi0PsR06YJERob7pZmzjIisVNW0Cqd5PQgAVJXcBQvY94c/Urx7N42vvooW//VfRLdqVaPbMfVXaV4ehdu2UbR1K4VbtlC0ZSuFW7dS9P33UFz8w4wiSEyM82gQTUSDmMBwRIMGSIMGPwzHNEAaxKBFReRnZlK8ezcAEQkJxPXuTXyfPsSn9SE2OZmImJgwvXJztrAgqKLSggIOvfgSh156CSIiaD5pEonptxHRoEFItmfqntL8fAo2fkvhd99RtHULhVu2Urh1C/7de36YKTKSBu3a0eCCC4jp2JEGF3Qk5oILaNChAxENGyIi1dp28Z495K1YSd7KFeSvXEnhd5sBkOhoYlNSAsEQ17s3kY0a1cTLNR5iQXCGinbuZN9jj5E7fwENzj+fFg/8FwmDB9vh+llG/X4Kv/uO/LVrKVi7lvy16yj87jtwLy2W2FgadOjww4d9xwuIuaAjDc4/H6mFLwf+w4fJ/+abQDgUrN8Afj9ERBDTpQvxqanE9fIRl5JC9HnnVTuAjDdYEFRT7pIv2DdtGkVZWUQlJdF42DCajBjutOHaf7p6RVUp/v578tespWDdWufvxo1oQQEAEU2aENezJ7HJPYlLTiamS1eiW5+LRNSd6ylK8/LIX7Pmh6OG1WvQvDwAIps2JTYlmbgUH3G+FOKSk4ls2jTMFZu6JCxBICKxwGIgBudOaO+q6tRy88QAbwB9gEPAGFXNqmy9tRkEAFpURM7Czzg6dy65ixdDcTExnTrRePi1NLn2WjuPUEcV799Pwbp1zrf9NWvJX7eO0qNHAeebfmz37sQl9yS2ZzJxKcn18hu1+v0UbtlC/urV5K9ZQ8HqNRRu3gzu/+kG559PXC8fsSkpxKX4iO3SuVaOZLxA/X78+/ZRWlhEVIukH9UkWFvCFQQCNFTVXBGJBr4AfqmqXwbNcxeQoqp3ishYYKSqjqlsvbUdBMH8hw+T8/HHHJ0zl/xvvgER4vv1o8nwa2l0xRXWbhsmJTk5zod+2bf9tevw793rTIyMJKZTJ+KSk51v+ykpxFx4IRJV7+7SWiUlubnOvli9hvw1a8hfs5qSA87vZKRBA2K7dyemW1catGlDdOvWRLduTVTr1kQ1b16njn7CTYuKKN67l+Jduyjevdv5u2v3D8P79gWaEAEkPp7opCSiWrRwHsHPWyQR7Y6LaNgwbK8p7E1DIhKPEwSTVPWroPGfAI+o6jIRiQL2AklaSVHhDIJgRd9/z9G5czk2Zy5F27cjMTEkXDqUJtcOJ2HgACQ6OtwlnpVKCwsp3LiR/DVryV/nfNsvysoKTI8+/zziklOcb/vJycR260ZEXFz4Cg4zVcW/Z48TCqvXkL96NYVbtgSOjspIgwZEn3su0W2cYCgLibLAiGrZ8qwJT1Wl5PBh/Pv2Ubx3r/N3954fPvB378a/f3/gyAqAiAiiWrZ09ksbd/+0aUNEbCz+/Qfw79+P/8B+ivfvDwyXNTsGi2jYMCgggkIi+JGURERsbI2/7rAFgYhEAiuBC4FnVfWBctPXAVeq6k53eAvQX1UPlptvIjAR4Lzzzuuzffsp78Fc61SVgrVrOfrBHI7Nm0fJ4cNENm1K46uvptEVVxCXkkxEfHy4y6yXSgsLKfy/7yjYuIGC9RvIX7uGwv/7zjlhCkQlJTnNHu6HflzPnkQ2aRLmquuHktxc5xvubvcbbvBj125Kyv/aPjKSqMREIhMTiUxsRlSzZkQ2c58nJhLpDkclNnPmadIkLMGhJSX4Dx7Cv9/9kN+7D/++vRTv3Yd/716K9+3Dv28fWlR04oJRUUS3akV00JFS4HnbNkS3bHlGX+5UldKcHDcgnGAIhMS+fYFx/v370eDLj10RTZoQ3SKJqBYtTwiNOF8v4nr2qNa+qQtHBE2B94HJqrouaHyVgiBYXTkiqIgWF5P7xRccmzuXnAULnR8LRUYS06Uz8b16EderF3E+X71sjw61kpwcCjZupHDjRgo2bHSeb90a+NCPaNyYuJ49iA36th/dsmWYqz57lRYWlguHXfgPHqQk+zAl2dnON+rDhyk9dqziFYgQ2bgxkYmJRMTFIdHRzqNBNBLdwP1bNq7BD8+jo8H9q0VFaEEhpQX5zt/CArSgEC0soDS/4IfhggJKCwvR/HxKCwqgtPTEUqKjiWrViuiWLZ2/rVoS1bIVUa1aOuNatiKq+TlhuSpQVSk5cuSHowr3yOKE4HDDhJISzpk4kRa/urda2wp7ELhFPAzkqer0oHH1tmnodEpyc8lfuZK8zEzyMzMpWL2G0rIrPBITifP5nEevXsQl9wxr22FtK96/3/nAD/rQL96xIzA9KimJmO7diO3Wjdhu3Ynt3o3otm0tPOsgLS7Gf/gwJYePUHI4m5LsbPzZhyk5fJiSw85zLShwPtSLi51H8PNTDAPOj/Pi4oiIiUFiY4mIjXX+VjQcF0tETCwSH+c0tbR0P/BbtSKyWbN6/97R0lJKsrOdI7Nmzaq1jsqCIGTHbiKSBBSr6hERiQP+A3i83GxzgNuAZcD1wMLKQqA+iUxIIGHwYBIGDwacQ9bCzVvIz8x0rvLIzCT3s8+cmd3rwuN8KcT16kVsly5Et2lDZOPGYXwF1aN+P/6DB53D8ODDcvdv0fffn9DsEH3+ecT26EHT668n1v3wj2rePIyvwJwJiY4mukULolu0qLF1qqpzIjYyst5/gNcUiYgI6f+LUF41lAK8DkTidG73tqo+KiKPAitUdY57iembQG8gGxirqlsrW299OSKoipIjR8hfu5b8b5yjhvw1ayjNzQ1Mj2jUyGmnbNOG6DbuibugR20EhZaUUHr8OKW5uZTk5lKae5zS47mUHD3mnGTb57TDlv31Hzhw8qF5bOwPh+WtWxPbratz9UrXrkQmJIT8NRhj6kjTUE05m4KgPC0tpWjLFgq3bnMvVzvxUda0VOaEoGjdmojYGFAl8G+qOFc+lD1wp50wvpTS43mUHC/7kHc+9Etzc50O1Mpts7yIhAS3rbVVub8tA+2yEU2a2Dc7Y8IsLE1D5sxJRAQxnToR06nTSdPKTioFrmUOvr55xw7yvvzSaVsV+eEBgecS9Dz4ISJExMcTkZBAREICkc2a0qBdWyIaJrjjGhLpTotomEBEowRnuFEjolq0sG/0xpwFLAjqCREhqplz2V51Lx8zxpiK2E8JjTHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG4ywIjDHG40IWBCLSTkQ+E5ENIrJeRH5ZwTxDROSoiGS6j4dDVY8xxpiKRYVw3X7gPlVdJSKNgJUi8qmqbig33xJVHRbCOowxxlQiZEcEqrpHVVe5z3OAjUCbUG3PGGNM9dTKOQIRaQ/0Br6qYPLFIrJaRD4SkR6nWH6iiKwQkRUHDhwIYaXGGOM9IQ8CEUkA/glMUdVj5SavAs5XVR/wNDC7onWo6guqmqaqaUlJSaEt2BhjPCakQSAi0TghMENV3ys/XVWPqWqu+3weEC0izUNZkzHGmBOF8qohAV4GNqrqX08xTyt3PkSkn1vPoVDVZIwx5mShvGroEuAWYK2IZLrjHgLOA1DV54HrgUki4gfygbGqqiGsyRhjTDkhCwJV/QKQ08zzDPBMqGowxhhzevbLYmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8TgLAmOM8bhQ3rzeGBNixcXF7Ny5k4KCgnCXYuqI2NhY2rZtS3R0dJWXsSAwph7buXMnjRo1on379ohIuMsxYaaqHDp0iJ07d9KhQ4cqL2dNQ8bUYwUFBZxzzjkWAgYAEeGcc8454yPEkAWBiLQTkc9EZIOIrBeRX1Ywj4jIUyKyWUTWiEhqqOox5mxlIWCCVef9EMojAj9wn6p2By4CfiEi3cvNcxXQyX1MBJ4LYT3GmBCZPXs2IsK3334b7lJMNYQsCFR1j6qucp/nABuBNuVmGwG8oY4vgaYicm6oajLGhEZGRgYDBgwgIyMjZNsoKSkJ2bq9rlbOEYhIe6A38FW5SW2AHUHDOzk5LBCRiSKyQkRWHDhwIFRlGmOqITc3ly+++IKXX36ZmTNnAs6H9q9//Wt69uxJSkoKTz/9NADLly/nJz/5CT6fj379+pGTk8Nrr73G3XffHVjfsGHDWLRoEQAJCQncd999+Hw+li1bxqOPPkrfvn3p2bMnEydORFUB2Lx5M5dffjk+n4/U1FS2bNnCrbfeyuzZswPrvemmm/jggw9qaa/ULyG/akhEEoB/AlNU9Vh11qGqLwAvAKSlpWkNlmfMWeO/565nw+5q/Rc7pe6tGzP12h6VzvPBBx9w5ZVX0rlzZ8455xxWrlzJ119/TVZWFpmZmURFRZGdnU1RURFjxoxh1qxZ9O3bl2PHjhEXF1fpuo8fP07//v35y1/+4tTTvTsPP/wwALfccgv/+te/uPbaa7npppt48MEHGTlyJAUFBZSWlvLzn/+cJ554guuuu46jR4+ydOlSXn/99ZrZMWeZkB4RiEg0TgjMUNX3KphlF9AuaLitO84YU09kZGQwduxYAMaOHUtGRgbz58/njjvuICrK+a6ZmJjIpk2bOPfcc+nbty8AjRs3Dkw/lcjISEaPHh0Y/uyzz+jfvz/JycksXLiQ9evXk5OTw65duxg5ciTgXEcfHx/P4MGD+e677zhw4AAZGRmMHj36tNvzqpDtFXFOXb8MbFTVv55itjnA3SIyE+gPHFXVPaGqyZiz2em+uYdCdnY2CxcuZO3atYgIJSUliEjgw74qoqKiKC0tDQwHX/oYGxtLZGRkYPxdd93FihUraNeuHY888shpL5O89dZbeeutt5g5cyavvvrqGb467wjlEcElwC3ApSKS6T6uFpE7ReROd555wFZgM/AicFcI6zHG1LB3332XW265he3bt5OVlcWOHTvo0KEDPp+Pv//97/j9fsAJjC5durBnzx6WL18OQE5ODn6/n/bt25OZmUlpaSk7duzg66+/rnBbZR/6zZs3Jzc3l3fffReARo0a0bZt28D5gMLCQvLy8gBIT0/nySefBJxmJVOx0x4RiMi1wIeqWnq6eYOp6hdApRe0qnOm5xdnsl5jTN2RkZHBAw88cMK40aNHs3HjRs477zxSUlKIjo5mwoQJ3H333cyaNYvJkyeTn59PXFwc8+fP55JLLqFDhw50796dbt26kZpa8c+JmjZtyoQJE+jZsyetWrU64ajjzTff5I477uDhhx8mOjqad955h44dO9KyZUu6devGddddF9L9UN9J2Vn3U84g8hZwMU5b/yuqGtYLhdPS0nTFihXhLMGYOmPjxo1069Yt3GXUWXl5eSQnJ7Nq1SqaNGkS7nJqTUXvCxFZqappFc1/2qYhVb0Z59LPLcBrIrLMvZyzUU0UbIwxoTB//ny6devG5MmTPRUC1VGlk8WqekxE3gXigCnASOB+EXlKVZ8OZYHGGFMdl19+Odu3bw93GfXCaY8IRGS4iLwPLAKigX6qehXgA+4LbXnGGGNCrSpHBKOBJ1R1cfBIVc0TkZ+HpixjjDG1pSpB8AgQuLZfROKAlqqapaoLQlWYMcaY2lGV3xG8AwRfOlrijjPGGHMWqEoQRKlqUdmA+7xB6EoyxtQXQ4cO5ZNPPjlh3JNPPsmkSZNOucyQIUMouwT86quv5siRIyfN88gjjzB9+vRKtz179mw2bNgQGH744YeZP3/+mZRfqSlTptCmTZsTfvV8tqpKEBwQkeFlAyIyAjgYupKMMfXFuHHjAj2Olpk5cybjxo2r0vLz5s2jadOm1dp2+SB49NFHufzyy6u1rvJKS0t5//33adeuHZ9//nmNrLMiZb+8DreqBMGdwEMi8r2I7AAeAO4IbVnGmPrg+uuv58MPP6SoyGk0yMrKYvfu3QwcOJBJkyaRlpZGjx49mDp1aoXLt2/fnoMHne+V06ZNo3PnzgwYMIBNmzYF5nnxxRfp27cvPp+P0aNHk5eXx9KlS5kzZw73338/vXr1YsuWLaSnpwe6nViwYAG9e/cmOTmZ8ePHU1hYGNje1KlTSU1NJTk5+ZQ30lm0aBE9evRg0qRJJ9xjYd++fYwcORKfz4fP52Pp0qUAvPHGG6SkpODz+bjlllsATqgHnC61y9Y9cOBAhg8fHuj24rrrrqNPnz706NGDF154IbDMxx9/TGpqKj6fj8suu4zS0lI6depEWXf8paWlXHjhhfzY7vlPe7JYVbcAF7ndSaOquT9qi8aY0PjoQdi7tmbX2SoZrnrslJMTExPp168fH330ESNGjGDmzJnceOONiAjTpk0jMTGRkpISLrvsMtasWUNKSkqF61m5ciUzZ84kMzMTv99Pamoqffr0AWDUqFFMmDABgN/+9re8/PLLTJ48meHDhzNs2DCuv/76E9ZVUFBAeno6CxYsoHPnztx6660899xzTJkyBXD6Klq1ahV/+9vfmD59Oi+99NJJ9WRkZDBu3DhGjBjBQw89RHFxMdHR0dxzzz0MHjyY999/n5KSEnJzc1m/fj2///3vWbp0Kc2bNyc7O/u0u3XVqlWsW7cucIP5V155hcTERPLz8+nbty+jR4+mtLSUCRMmsHjxYjp06EB2djYRERHcfPPNzJgxgylTpjB//nx8Ph9JSUmn3WZlqtTpnIhcg9Mh3K9E5GERefhHbdUYc9YIbh4KbhZ6++23SU1NpXfv3qxfv/6EZpzylixZwsiRI4mPj6dx48YMHx5ojWbdunUMHDiQ5ORkZsyYwfr16yutZ9OmTXTo0IHOnTsDcNttt7F48Q9Xv48aNQqAPn36kJWVddLyRUVFzJs3j+uuu47GjRvTv3//wHmQhQsXBs5/REZG0qRJExYuXMgNN9xA8+bNASccT6dfv36BEAB46qmn8Pl8XHTRRezYsYPvvvuOL7/8kkGDBgXmK1vv+PHjeeONNwAnQH72s5+ddnunU5VO554H4oGhwEvA9UDF3QMaY8Knkm/uoTRixAjuvfdeVq1aRV5eHn369GHbtm1Mnz6d5cuX06xZM9LT00/bZfSppKenM3v2bHw+H6+99lrg7mXVFRMTAzgf5BW10X/yySccOXKE5ORkwOmvKC4ujmHDhp3RdoK71y4tLQ00nwE0bNgw8HzRokXMnz+fZcuWER8fz5AhQyrdV+3ataNly5YsXLiQr7/+mhkzZpxRXRWpyhHBT1T1VuCwqv43Tgd0nX/0lo0xZ4WEhASGDh3K+PHjA0cDx44do2HDhjRp0oR9+/bx0UcfVbqOQYMGMXv2bPLz88nJyWHu3LmBaTk5OZx77rkUFxef8KHXqFEjcnJyTlpXly5dyMrKYvPmzYDTM+ngwYOr/HoyMjJ46aWXyMrKIisri23btvHpp5+Sl5fHZZddxnPPPQc4t+M8evQol156Ke+88w6HDh0CCDQNtW/fnpUrVwIwZ84ciouLK9ze0aNHadasGfHx8Xz77bd8+eWXAFx00UUsXryYbdu2nbBegNtvv52bb76ZG264IXC/hh+jKkFQFk15ItIaKAbsBvPGmIBx48axevXqQBD4fD569+5N165d+elPf8oll1xS6fKpqamMGTMGn8/HVVdddUIX07/73e/o378/l1xyCV27dg2MHzt2LH/+85/p3bs3W7ZsCYyPjY3l1Vdf5YYbbiA5OZmIiAjuvPNOqiIvL4+PP/6Ya665JjCuYcOGDBgwgLlz5/I///M/fPbZZyQnJ9OnTx82bNhAjx49+M1vfsPgwYPx+Xz86le/AmDChAl8/vnngfstBx8FBLvyyivx+/1069aNBx98kIsuugiApKQkXnjhBUaNGoXP52PMmDGBZYYPH05ubm6NNAtB1bqh/n/A08BlwLOAAi+qaljOE1g31Mb8wLqh9qYVK1Zw7733smTJkgqnn2k31JWeIxCRCGCBqh4B/iki/wJiVfVotao3xhjzozz22GM899xzNXJuoEylTUPuXcmeDRoutBAwxpjwefDBB9m+fTsDBgyosXVW5RzBAhEZ7d6M3hhjzFmmKkFwB04nc4UickxEckTkWIjrMsYYU0uq8stiuyWlMcacxaryg7JBFY0vf6MaY4wx9VNVbkxzf9DzWKAfsBK4tLKFROQVYBiwX1V7VjB9CPABsM0d9Z6qPlqFeowxdURCQgK5udb9WH1Xlaaha4OHRaQd8GQV1v0a8AzwRiXzLFHVM/vdtjHGmBpVpU7nytkJnPYXLG7T0em74TPG1Huqyv3330/Pnj1JTk5m1qxZAOzZs4dBgwbRq1cvevbsyZIlSygpKSE9PT0w7xNPPBHm6k1VzhE8jfNrYnCCoxewqoa2f7GIrAZ2A79W1Qq7FRSRicBEgPPOO6+GNm3M2eXxrx/n2+yK+9evrq6JXXmg3wOnne+9994jMzOT1atXc/DgQfr27cugQYP4xz/+wX/+53/ym9/8hpKSEvLy8sjMzGTXrl2sW7cOoMI7lJnaVZVzBMH9OfiBDFX9dw1sexVwvqrmisjVwGygU0UzquoLwAvgdDFRA9s2xtSgL774gnHjxhEZGUnLli0ZPHgwy5cvp2/fvowfP57i4mKuu+46evXqRceOHdm6dSuTJ0/mmmuu4Yorrgh3+Z5XlSB4F3eeab8AABGoSURBVChQ1RIAEYkUkXhVzfsxG1bVY0HP54nI30SkuarabTCNqYaqfHOvbYMGDWLx4sV8+OGHpKen86tf/Ypbb72V1atX88knn/D888/z9ttv88orr4S7VE+r0i+Lgbig4TjgR98hWkRalf1aWUT6ubUc+rHrNcbUvoEDBzJr1ixKSko4cOAAixcvpl+/fmzfvp2WLVsyYcIEbr/9dlatWsXBgwcpLS1l9OjR/P73v2fVqppqaTbVVZUjgtjg21O6TTnxp1tIRDKAIUBzEdkJTAWi3XU8j3ODm0ki4gfygbF6uq5QjTF10siRI1m2bBk+nw8R4U9/+hOtWrXi9ddf589//jPR0dEkJCTwxhtvsGvXLn72s58Fbtryxz/+MczVm6p0Q/1vYLKqrnKH+wDPqOrFtVDfSawbamN+YN1Qm4rUaDfUrinAOyKyGxCgFTCm8kWMMcbUF1X5QdlyEekKdHFHbVLViu+5Zowxpt457cliEfkF0FBV16nqOiBBRO4KfWnGGGNqQ1WuGprg3qEMAFU9DEwIXUnGGGNqU1WCIDL4pjQiEgk0CF1JxhhjalNVThZ/DMwSkb+7w3cAH4WuJGOMMbWpKkcEDwALgTvdx1pO/IGZMcajhg4dyieffHLCuCeffJJJkyadcpkhQ4ZQdgn41VdfXWFfQ4888gjTp0+vdNuzZ89mw4YNgeGHH36Y+fN/9G9dWbRoEcOGeatT5NMGgXsD+6+ALJx7EVwKbAxtWcaY+mDcuHHMnDnzhHEzZ85k3LhxVVp+3rx5NG3atFrbLh8Ejz76KJdffnm11uV1pwwCEeksIlNF5FvgaeB7AFUdqqrP1FaBxpi66/rrr+fDDz+kqKgIgKysLHbv3s3AgQOZNGkSaWlp9OjRg6lTp1a4fPv27Tl40OlebNq0aXTu3JkBAwawadOmwDwvvvgiffv2xefzMXr0aPLy8li6dClz5szh/vvvp1evXmzZsoX09HTeffddABYsWEDv3r1JTk5m/PjxFBYWBrY3depUUlNTSU5O5ttvq95ba0ZGBsnJyfTs2ZMHHnD6dTpVl9pPPfUU3bt3JyUlhbFjx57hXq19lZ0j+BZYAgxT1c0AInJvrVRljDlje//wBwo31mw31DHdutLqoYdOOT0xMZF+/frx0UcfMWLECGbOnMmNN96IiDBt2jQSExMpKSnhsssuY82aNaSkpFS4npUrVzJz5kwyMzPx+/2kpqbSp08fAEaNGsWECc6Fir/97W95+eWXmTx5MsOHD2fYsGFcf/31J6yroKCA9PR0FixYQOfOnbn11lt57rnnmDJlCgDNmzdn1apV/O1vf2P69Om89NJLp90Pu3fv5oEHHmDlypU0a9aMK664gtmzZ9OuXbsKu9R+7LHH2LZtGzExMfWim+3KmoZGAXuAz0TkRRG5DOeXxcYYExDcPBTcLPT222+TmppK7969Wb9+/QnNOOUtWbKEkSNHEh8fT+PGjRk+fHhg2rp16xg4cCDJycnMmDGD9esrvG1JwKZNm+jQoQOdO3cG4LbbbmPx4h9usT5q1CgA+vTpQ1ZWVpVe4/LlyxkyZAhJSUlERUVx0003sXjx4hO61P74449p3LgxACkpKdx000289dZbREVV5Zqc8Dplhao6G5gtIg2BEThdTbQQkeeA91X1f2upRmNMFVT2zT2URowYwb333suqVavIy8ujT58+bNu2jenTp7N8+XKaNWtGeno6BQUF1Vp/eno6s2fPxufz8dprr7Fo0aIfVW9MTAwAkZGR+P3+H7WuZs2aVdil9ocffsjixYuZO3cu06ZNY+3atXU6EKpysvi4qv7DvXdxW+AbnCuJjDGGhIQEhg4dyvjx4wNHA8eOHaNhw4Y0adKEffv28dFHlV9xPmjQIGbPnk1+fj45OTnMnTs3MC0nJ4dzzz2X4uJiZsyYERjfqFEjcnJyTlpXly5dyMrKYvPmzQC8+eabDB48+Ee9xn79+vH5559z8OBBSkpKyMjIYPDgwRV2qV1aWsqOHTsYOnQojz/+OEePHiU3N/f0GwmjM4oo91fFgbuFGWMMOM1DI0eODDQR+Xw+evfuTdeuXWnXrh2XXHJJpcunpqYyZswYfD4fLVq0oG/fvoFpv/vd7+jfvz9JSUn0798/8OE/duxYJkyYwFNPPRU4SQwQGxvLq6++yg033IDf76dv377ceeedZ/R6FixYQNu2bQPD77zzDo899hhDhw5FVbnmmmsYMWIEq1evPqlL7ZKSEm6++WaOHj2KqnLPPfdU+8qo2nLabqjrGuuG2pgfWDfUpiJn2g11VX5QZowx5ixmQWCMMR5nQWCMMR5nQWBMPVffzvOZ0KrO+8GCwJh6LDY2lkOHDlkYGMAJgUOHDhEbG3tGy9XdXzgYY06rbdu27Ny5kwMHDoS7FFNHxMbGnnDpa1VYEBhTj0VHR9OhQ4dwl2HquZA1DYnIKyKyX0TWnWK6iMhTIrJZRNaISGqoajHGGHNqoTxH8BpwZSXTrwI6uY+JwHMhrMUYY8wphKxpSFUXi0j7SmYZAbyhzlmuL0WkqYicq6p7QlHPf89dz4bdx0KxamOMqRXdWzdm6rU9any94bxqqA2wI2h4pzvuJCIyUURWiMgKOylmjDE1q16cLFbVQEd3aWlp1bpOLhQpaowxZ4NwHhHsAtoFDbd1xxljjKlF4QyCOcCt7tVDFwFHQ3V+wBhjzKmFrGlIRDKAIUBzEdkJTAWiAVT1eWAecDWwGcgDfhaqWowxxpxaKK8aGnea6Qr8IlTbDyt/Eax/H/asDncldU98IvS+GRq1CnclxhhXvThZXG/kZcPKV+GrFyB3L0THg0SGu6q6pSgXFj0GyTfAxb+AVj3DXZExnmdBUBMObYEvn4PMGVCcBx2HwnXPwgWXgUi4q6tbsrfCl8/DN2/B6n9AxyFw8WS40PaVMeFit6qsLlX4/ktY9gx8+yFEREHKjc633JZ2qepp5R+Gla/BV3+HnD2Q1NXZd8k3QvSZ9ZxojDm9ym5VaUFwpkr8sPEDWPYs7FoJcc0g7efQb4K1e1dH2fmUZU/D3rUQ39zZl31vh4bNw12dMWcNC4KaUHAMVr0BXz0PR3dA4gVw8V3g+yk0iK/9es42qrBtsROw330CUbHgGwsX/QKSOoe7OmPqvcqCwDvnCI58D9uXVm/ZvWudECg8BudfAlf9CTpfCRF2X58aIwIdBzuPA5vgy7/B6plO81Gn/4Tuw53mN2O8LKkrtO5V46v1zv+sXSvh/Tuqt6xEQo+RTht2G+stO+SSusC1/wOX/j9Y/jJ8/YJzlGCM110yJSRB4J2mocJcOL6/ehuNbepc/27Cw18Ix6z3EWN+zGeRNQ0BxCQ4D1P/RMVAYsdwV2HMWcsauY0xxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuMsCIwxxuNCGgQicqWIbBKRzSLyYAXT00XkgIhkuo/bQ1mPMcaYk4WsG2oRiQSeBf4D2AksF5E5qrqh3KyzVPXuUNVhjDGmcqE8IugHbFbVrapaBMwERoRwe8YYY6ohlEHQBtgRNLzTHVfeaBFZIyLviki7ilYkIhNFZIWIrDhw4EAoajXGGM8K98niuUB7VU0BPgVer2gmVX1BVdNUNS0pKalWCzTGmLNdKINgFxD8Db+tOy5AVQ+paqE7+BLQJ4T1GGOMqUAog2A50ElEOohIA2AsMCd4BhE5N2hwOLAxhPUYY4ypQMiuGlJVv4jcDXwCRAKvqOp6EXkUWKGqc4B7RGQ44AeygfRQ1WOMMaZioqrhruGMpKWl6YoVK8JdhjHG1CsislJV0yqaFu6TxcYYY8LMgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzwupEEgIleKyCYR2SwiD1YwPUZEZrnTvxKR9qGsxxhjzMlCFgQiEgk8C1wFdAfGiUj3crP9HDisqhcCTwCPh6oeY4wxFYsK4br7AZtVdSuAiMwERgAbguYZATziPn8XeEZERFW1pot5/OvH+Tb725perTHG1JquiV15oN8DNb7eUDYNtQF2BA3vdMdVOI+q+oGjwDnlVyQiE0VkhYisOHDgQIjKNcYYbwrlEUGNUdUXgBcA0tLSqnW0EIoUNcaYs0Eojwh2Ae2Chtu64yqcR0SigCbAoRDWZIwxppxQBsFyoJOIdBCRBsBYYE65eeYAt7nPrwcWhuL8gDHGmFMLWdOQqvpF5G7gEyASeEVV14vIo8AKVZ0DvAy8KSKbgWycsDDGGFOLQnqOQFXnAfPKjXs46HkBcEMoazDGGFM5+2WxMcZ4nAWBMcZ4nAWBMcZ4nAWBMcZ4nNS3qzVF5ACwvZqLNwcO1mA5ZwvbLyezfXIy2ycnq0/75HxVTapoQr0Lgh9DRFaoalq466hrbL+czPbJyWyfnOxs2SfWNGSMMR5nQWCMMR7ntSB4IdwF1FG2X05m++Rktk9OdlbsE0+dIzDGGHMyrx0RGGOMKceCwBhjPM4zQSAiV4rIJhHZLCIPhrueukBEskRkrYhkisiKcNcTLiLyiojsF5F1QeMSReRTEfnO/dssnDXWtlPsk0dEZJf7fskUkavDWWNtE5F2IvKZiGwQkfUi8kt3fL1/r3giCEQkEngWuAroDowTke7hrarOGKqqvc6Ga6F/hNeAK8uNexBYoKqdgAXusJe8xsn7BOAJ9/3Sy+1d2Ev8wH2q2h24CPiF+zlS798rnggCoB+wWVW3qmoRMBMYEeaaTB2hqotx7ocRbATwuvv8deC6Wi0qzE6xTzxNVfeo6ir3eQ6wEee+6/X+veKVIGgD7Aga3umO8zoF/ldEVorIxHAXU8e0VNU97vO9QMtwFlOH3C0ia9ymo3rXBFJTRKQ90Bv4irPgveKVIDAVG6CqqThNZr8QkUHhLqgucm+fatdZw3PABUAvYA/wl/CWEx4ikgD8E5iiqseCp9XX94pXgmAX0C5ouK07ztNUdZf7dz/wPk4TmnHsE5FzAdy/+8NcT9ip6j5VLVHVUuBFPPh+EZFonBCYoarvuaPr/XvFK0GwHOgkIh1EpAHOvZHnhLmmsBKRhiLSqOw5cAWwrvKlPGUOcJv7/DbggzDWUieUfdi5RuKx94uICM591jeq6l+DJtX794pnflnsXur2JBAJvKKq08JcUliJSEecowBw7l39D6/uExHJAIbgdCm8D5gKzAbeBs7D6fb8RlX1zMnTU+yTITjNQgpkAXcEtY2f9URkALAEWAuUuqMfwjlPUK/fK54JAmOMMRXzStOQMcaYU7AgMMYYj7MgMMYYj7MgMMYYj7MgMMYYj7MgMKYcESkJ6mEzsyZ7qxWR9sE9ehpTF0SFuwBj6qB8Ve0V7iKMqS12RGBMFbn3b/iTew+Hr0XkQnd8exFZ6HbGtkBEznPHtxSR90Vktfv4ibuqSBF50e3T/n9FJC5sL8oYLAiMqUhcuaahMUHTjqpqMvAMzi/VAZ4GXlfVFGAG8JQ7/ingc1X1AanAend8J+BZVe0BHAFGh/j1GFMp+2WxMeWISK6qJlQwPgu4VFW3up2P7VXVc0TkIHCuqha74/eoanMROQC0VdXCoHW0Bz51b2KCiDwARKvq70P/yoypmB0RGHNm9BTPz0Rh0PMS7FydCTMLAmPOzJigv8vc50txerQFuAmnYzJwbls4CZzbpYpIk9oq0pgzYd9EjDlZnIhkBg1/rKpll5A2E5E1ON/qx7njJgOvisj9wAHgZ+74XwIviMjPcb75T8K5oYsxdYqdIzCmitxzBGmqejDctRhTk6xpyBhjPM6OCIwxxuPsiMAYYzzOgsAYYzzOgsAYYzzOgsAYYzzOgsAYYzzu/wNjrbHFhUG2yAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PA5jf1eNZUu"
      },
      "source": [
        "#lenet\n",
        "lenet_model = keras.models.Sequential([\n",
        "    keras.layers.Conv2D(6, kernel_size=5, strides=1,  activation='relu', input_shape=train_x[0].shape, padding='same'), #C1\n",
        "    keras.layers.AveragePooling2D(), #S2\n",
        "    keras.layers.Conv2D(16, kernel_size=5, strides=1, activation='relu', padding='same'), #C3\n",
        "    keras.layers.AveragePooling2D(), #S4\n",
        "    keras.layers.Flatten(), #Flatten\n",
        "    keras.layers.Dense(120, activation='relu'), #C5\n",
        "    keras.layers.Dense(84, activation='relu'), #F6\n",
        "    keras.layers.Dense(3, activation='softmax') #Output layer\n",
        "])"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A09Ou3hIOEbV"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "opt = Adam(lr=0.001)\n",
        "lenet_model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBlH2QRBOelA",
        "outputId": "e841ecb1-ea77-48c0-da5f-f6aaea45f1ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "checkpoint = ModelCheckpoint(\"lenet_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "\n",
        "lenet=lenet_model.fit(train_x,train_y,batch_size = 32,epochs=100,verbose=1,validation_data=(eval_x, eval_y),callbacks=[checkpoint,early])\n",
        "lenet"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - ETA: 0s - loss: 1.3111 - accuracy: 0.3500\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 0s 104ms/step - loss: 1.3111 - accuracy: 0.3500 - val_loss: 0.8845 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.9797 - accuracy: 0.5000\n",
            "Epoch 00002: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.9363 - accuracy: 0.5000 - val_loss: 0.8203 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.8936 - accuracy: 0.4688\n",
            "Epoch 00003: val_accuracy did not improve from 0.50000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.8108 - accuracy: 0.6000 - val_loss: 0.9397 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.7526 - accuracy: 0.5000\n",
            "Epoch 00004: val_accuracy improved from 0.50000 to 1.00000, saving model to lenet_1.h5\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.7113 - accuracy: 0.6500 - val_loss: 0.6248 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.5048 - accuracy: 1.0000\n",
            "Epoch 00005: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.4551 - accuracy: 0.9875 - val_loss: 0.3073 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.3963 - accuracy: 0.8438\n",
            "Epoch 00006: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.2727 - accuracy: 0.9250 - val_loss: 0.0967 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.1219 - accuracy: 1.0000\n",
            "Epoch 00007: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 0.1143 - accuracy: 0.9875 - val_loss: 0.0786 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 00008: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.9875 - val_loss: 0.1723 - val_accuracy: 0.9000\n",
            "Epoch 9/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0513 - accuracy: 1.0000\n",
            "Epoch 00009: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0616 - accuracy: 0.9875 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0906 - accuracy: 0.9375\n",
            "Epoch 00010: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0428 - accuracy: 0.9750 - val_loss: 0.0376 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0208 - accuracy: 1.0000\n",
            "Epoch 00011: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 00012: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 00013: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 14/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0180 - accuracy: 1.0000\n",
            "Epoch 00014: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "Epoch 00015: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 4.4867e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 6.2729e-04 - accuracy: 1.0000\n",
            "Epoch 00016: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 8.4071e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 7.2863e-04 - accuracy: 1.0000\n",
            "Epoch 00017: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.5766e-04 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 8.0877e-04 - accuracy: 1.0000\n",
            "Epoch 00018: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 13ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "Epoch 00019: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 3.5326e-04 - accuracy: 1.0000\n",
            "Epoch 00020: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.3780e-04 - accuracy: 1.0000 - val_loss: 8.1428e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 1.5441e-04 - accuracy: 1.0000\n",
            "Epoch 00021: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 3.6756e-04 - accuracy: 1.0000 - val_loss: 3.2885e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 7.2671e-04 - accuracy: 1.0000\n",
            "Epoch 00022: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 4.6135e-04 - accuracy: 1.0000 - val_loss: 2.4946e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 5.4252e-04 - accuracy: 1.0000\n",
            "Epoch 00023: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 11ms/step - loss: 5.2347e-04 - accuracy: 1.0000 - val_loss: 2.4324e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "1/3 [=========>....................] - ETA: 0s - loss: 2.6549e-04 - accuracy: 1.0000\n",
            "Epoch 00024: val_accuracy did not improve from 1.00000\n",
            "3/3 [==============================] - 0s 12ms/step - loss: 4.4818e-04 - accuracy: 1.0000 - val_loss: 2.6646e-04 - val_accuracy: 1.0000\n",
            "Epoch 00024: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4e200e9c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd4Rz9K4O4_i",
        "outputId": "df8025f6-6275-4bd3-b530-271d08a39159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Once the model is trained we can evaluate it on Test data.\n",
        "\n",
        "# Evaluating the model \n",
        "lenetscore = lenet_model.evaluate(test_x, test_y, verbose=0)\n",
        "print('Test Loss:', lenetscore[0])\n",
        "print('Test accuracy:', lenetscore[1])"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.08363452553749084\n",
            "Test accuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4ymiRWGO-kY",
        "outputId": "9de6d6ea-a865-4a68-c078-45304f912eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "lenet_pred = classifier.predict(test_x)\n",
        "y_pred = np.argmax(lenet_pred, axis=1)\n",
        "target_names = ['class 0(car)', 'class 1(bike)','class 2(random)']\n",
        "                                               \n",
        "print(classification_report(np.argmax(test_y,axis=1), y_pred,target_names=target_names))\n",
        "\n",
        "print(confusion_matrix(np.argmax(test_y,axis=1), y_pred))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "   class 0(car)       1.00      0.50      0.67         2\n",
            "  class 1(bike)       1.00      1.00      1.00         3\n",
            "class 2(random)       0.83      1.00      0.91         5\n",
            "\n",
            "       accuracy                           0.90        10\n",
            "      macro avg       0.94      0.83      0.86        10\n",
            "   weighted avg       0.92      0.90      0.89        10\n",
            "\n",
            "[[1 0 1]\n",
            " [0 3 0]\n",
            " [0 0 5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiWvGyjTQKSz",
        "outputId": "e6beac88-1790-4b59-acad-9767c42f9474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(lenet.history[\"accuracy\"])\n",
        "plt.plot(lenet.history['val_accuracy'])\n",
        "plt.plot(lenet.history['loss'])\n",
        "plt.plot(lenet.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "plt.show()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}